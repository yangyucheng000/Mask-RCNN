{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad970dc6",
   "metadata": {},
   "source": [
    "# 模型介绍\n",
    "Mask R-CNN通过添加一个与现有目标检测框回归并行的，用于预测目标掩码的分支来扩展Faster R-CNN，通过添加一个用于在每个感兴趣区域（RoI）上预测分割掩码的分支来扩展Faster R-CNN，就是在每个感兴趣区域（RoI）进行一个二分类的语义分割，在这个感兴趣区域同时做目标检测和分割，这个分支与用于分类和目标检测框回归的分支并行执行，如下图所示（用于目标分割的Mask R-CNN框架）：\n",
    "![model](img/model.jpg)\n",
    "掩码分支是作用于每个RoI的小FCN，以像素到像素的方式预测分割掩码，可是要在ROI区域进行一个mask分割，存在一个问题，Faster R-CNN不是为网络输入和输出之间的像素到像素对齐而设计的，如果直接拿Faster R-CNN得到的ROI进行mask分割，那么像素到像素的分割可能不精确，因为应用到目标检测上的核心操作执行的是粗略的空间量化特征提取，直接分割出来的mask存在错位的情况，所以作者提出了简单的，量化无关的层，称为RoIAlign(ROI对齐)，可以保留精确的空间位置，可以将掩码(mask)准确度提高10％至50％。\n",
    "[论文:](http://cn.arxiv.org/pdf/1703.06870v3)\"MaskRCNN\"\n",
    "\n",
    "## 模型结构\n",
    "Mask R-CNN由两个阶段组成，称为区域提议网络（RPN）的第一阶段提出候选目标边界框。第二阶段本质上就是Fast R-CNN，它使用来自候选框架中的RoIPool来提取特征并进行分类和边界框回归，Mask R-CNN还为每个RoI输出二进制掩码。\n",
    "![framework](img/framework.jpg)\n",
    "模型整体结构组成为：骨干网络，特征金字塔网络(FPN)、区域提议网络以及Fast R-CNN。骨干网络和特征金字塔网络提取出图像的特征，然后区域提议网络在特征图上筛选出候选框，结合特征图和候选框后进行RoI Align，此后送入三个分支网络，分别获取分类结果、目标框以及目标区域的mask。\n",
    "\n",
    "下图是以ResNet50为骨干网络加上FPN的网络结构：\n",
    "![](img/resnet%2Bfpn.jpg)\n",
    "\n",
    "此处推荐三个视频用于读者加深理解：[FPN](https://www.bilibili.com/video/BV1dh411U7D9?vd_source=2277cd0edf083354294094185f8857ab)、[Faster RCNN](https://www.bilibili.com/video/BV1af4y1m7iL?p=3&vd_source=2277cd0edf083354294094185f8857ab)、[Mask RCNN](https://www.bilibili.com/video/BV1ZY411774T?vd_source=2277cd0edf083354294094185f8857ab)。\n",
    "\n",
    "## 模型优点\n",
    "Mask R-CNN训练简单，只增加了Faster R-CNN少量的开销即可处理语义分割问题，运行速度为5fps。此外Mask R-CNN易于推广到其它任务中。\n",
    "\n",
    "# 案例实现\n",
    "## 环境准备与数据读取\n",
    "本案例基于MindSpore-GPU版本实现，在GPU上完成模型训练。\n",
    "\n",
    "案例实现所使用的数据为coco数据集，可从https://cocodataset.org/#download下载，需要下载对应的Image和Annotations。下载下来的Annotations的结构如图:\n",
    "![](img/struct.jpg)\n",
    "若需要调整训练所用的数据量，只需要调整image的选项即可。\n",
    "\n",
    "**注意事项**：本案例需要安装pycocotools，若在windows上，使用``pip install pycocotools``安装会提示缺少c++库，可以使用``pip install pycocotools-windows``安装。在linux下安装时，可能会报缺少Cython的错误，先使用``pip install cython``安装好Cython即可。\n",
    "\n",
    "## 数据集创建\n",
    "接来下是创建数据集部分，首先需要将Annotations中的instances_(train/val)2017.json文件读入内存，然后根据images中的图片信息读取图片并解析mask信息然后将这些信息存入mindrecord文件(用于加速数据读取)。最后根据设定的batch size等信息创建MindDataset并组织数据成需要的形式，此过程会返回一个指向数据集的迭代器。至此完成数据集的创建，上述过程的代码对应如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3587b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mindspore import context\n",
    "import mindspore.nn as nn\n",
    "from mindspore.ops import operations as P\n",
    "from mindspore.common.tensor import Tensor\n",
    "from mindspore.ops import functional as F\n",
    "from mindspore.ops import composite as C\n",
    "from mindspore.nn import layer as L\n",
    "from mindspore.nn import Momentum\n",
    "from mindspore.common.parameter import Parameter\n",
    "from mindspore.common.initializer import initializer\n",
    "import mindspore.common.dtype as mstype\n",
    "import os\n",
    "import time\n",
    "from numpy import random\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools import mask as maskUtils\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import mindspore.dataset as de\n",
    "from mindspore.mindrecord import FileWriter\n",
    "import mindspore.dataset.vision as vision\n",
    "from mindspore import ParameterTuple\n",
    "import mindspore.ops as ops\n",
    "import mindspore as ms\n",
    "import matplotlib.pyplot as plt\n",
    "from mindspore.train import Model\n",
    "from mindspore.train.callback import Callback\n",
    "from mindspore.train.callback import CheckpointConfig, ModelCheckpoint, TimeMonitor\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np_cast_type = np.float32\n",
    "time_stamp_init = time.time()\n",
    "time_stamp_first = time.time()\n",
    "\n",
    "\n",
    "def create_coco_label(is_training):\n",
    "    \"\"\"Get image path and annotation from COCO.\"\"\"\n",
    "    from pycocotools.coco import COCO\n",
    "\n",
    "    coco_root = config.coco_root\n",
    "    data_type = config.val_data_type\n",
    "    if is_training:\n",
    "        data_type = config.train_data_type\n",
    "\n",
    "    # Classes need to train or test.\n",
    "    train_cls = config.coco_classes\n",
    "\n",
    "    train_cls_dict = {}\n",
    "    for i, cls in enumerate(train_cls):\n",
    "        train_cls_dict[cls] = i\n",
    "\n",
    "    anno_json = os.path.join(coco_root, config.instance_set.format(data_type))\n",
    "\n",
    "    coco = COCO(anno_json)\n",
    "    classs_dict = {}\n",
    "    cat_ids = coco.loadCats(coco.getCatIds())\n",
    "    for cat in cat_ids:\n",
    "        classs_dict[cat[\"id\"]] = cat[\"name\"]\n",
    "\n",
    "    image_ids = coco.getImgIds()\n",
    "    image_files = []\n",
    "    image_anno_dict = {}\n",
    "    masks = {}\n",
    "    masks_shape = {}\n",
    "    images_num = len(image_ids)\n",
    "    for ind, img_id in enumerate(image_ids):\n",
    "        image_info = coco.loadImgs(img_id)\n",
    "        file_name = image_info[0][\"file_name\"]\n",
    "        image_path = os.path.join(coco_root, data_type, file_name)\n",
    "        if not os.path.isfile(image_path):\n",
    "            print(\"{}/{}: {} is in annotations but not exist\".format(ind + 1, images_num, image_path))\n",
    "            continue\n",
    "        anno_ids = coco.getAnnIds(imgIds=img_id, iscrowd=None)\n",
    "        anno = coco.loadAnns(anno_ids)\n",
    "        image_path = os.path.join(coco_root, data_type, file_name)\n",
    "        annos = []\n",
    "        instance_masks = []\n",
    "        image_height = coco.imgs[img_id][\"height\"]\n",
    "        image_width = coco.imgs[img_id][\"width\"]\n",
    "        if (ind + 1) % 10 == 0:\n",
    "            print(\"{}/{}: parsing annotation for image={}\".format(ind + 1, images_num, file_name))\n",
    "        if not is_training:\n",
    "            image_files.append(image_path)\n",
    "            image_anno_dict[image_path] = np.array([0, 0, 0, 0, 0, 1])\n",
    "            masks[image_path] = np.zeros([1, 1, 1], dtype=bool).tobytes()\n",
    "            masks_shape[image_path] = np.array([1, 1, 1], dtype=np.int32)\n",
    "        else:\n",
    "            for label in anno:\n",
    "                bbox = label[\"bbox\"]\n",
    "                class_name = classs_dict[label[\"category_id\"]]\n",
    "                if class_name in train_cls:\n",
    "                    # get coco mask\n",
    "                    m = annToMask(label, image_height, image_width)\n",
    "                    if m.max() < 1:\n",
    "                        print(\"all black mask!!!!\")\n",
    "                        continue\n",
    "                    # Resize mask for the crowd\n",
    "                    if label['iscrowd'] and (m.shape[0] != image_height or m.shape[1] != image_width):\n",
    "                        m = np.ones([image_height, image_width], dtype=bool)\n",
    "                    instance_masks.append(m)\n",
    "\n",
    "                    # get coco bbox\n",
    "                    x1, x2 = bbox[0], bbox[0] + bbox[2]\n",
    "                    y1, y2 = bbox[1], bbox[1] + bbox[3]\n",
    "                    annos.append([x1, y1, x2, y2] + [train_cls_dict[class_name]] + [int(label[\"iscrowd\"])])\n",
    "                else:\n",
    "                    print(\"not in classes: \", class_name)\n",
    "\n",
    "            image_files.append(image_path)\n",
    "            if annos:\n",
    "                image_anno_dict[image_path] = np.array(annos)\n",
    "                instance_masks = np.stack(instance_masks, axis=0).astype(bool)\n",
    "                masks[image_path] = np.array(instance_masks).tobytes()\n",
    "                masks_shape[image_path] = np.array(instance_masks.shape, dtype=np.int32)\n",
    "            else:\n",
    "                print(\"no annotations for image \", file_name)\n",
    "                image_anno_dict[image_path] = np.array([0, 0, 0, 0, 0, 1])\n",
    "                masks[image_path] = np.zeros([1, image_height, image_width], dtype=bool).tobytes()\n",
    "                masks_shape[image_path] = np.array([1, image_height, image_width], dtype=np.int32)\n",
    "\n",
    "    return image_files, image_anno_dict, masks, masks_shape\n",
    "\n",
    "\n",
    "def data_to_mindrecord_byte_image(dataset=\"coco\", is_training=True, prefix=\"maskrcnn.mindrecord\", file_num=8):\n",
    "    \"\"\"Create MindRecord file.\"\"\"\n",
    "    mindrecord_dir = config.mindrecord_dir\n",
    "    mindrecord_path = os.path.join(mindrecord_dir, prefix)\n",
    "\n",
    "    writer = FileWriter(mindrecord_path, file_num)\n",
    "    if dataset == \"coco\":\n",
    "        image_files, image_anno_dict, masks, masks_shape = create_coco_label(is_training)\n",
    "    else:\n",
    "        print(\"Error unsupported other dataset\")\n",
    "        return\n",
    "\n",
    "    maskrcnn_json = {\n",
    "        \"image\": {\"type\": \"bytes\"},\n",
    "        \"annotation\": {\"type\": \"int32\", \"shape\": [-1, 6]},\n",
    "        \"mask\": {\"type\": \"bytes\"},\n",
    "        \"mask_shape\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    }\n",
    "    writer.add_schema(maskrcnn_json, \"maskrcnn_json\")\n",
    "\n",
    "    image_files_num = len(image_files)\n",
    "    for ind, image_name in enumerate(image_files):\n",
    "        with open(image_name, 'rb') as f:\n",
    "            img = f.read()\n",
    "        annos = np.array(image_anno_dict[image_name], dtype=np.int32)\n",
    "        mask = masks[image_name]\n",
    "        mask_shape = masks_shape[image_name]\n",
    "        row = {\"image\": img, \"annotation\": annos, \"mask\": mask, \"mask_shape\": mask_shape}\n",
    "        if (ind + 1) % 10 == 0:\n",
    "            print(\"writing {}/{} into mindrecord\".format(ind + 1, image_files_num))\n",
    "        writer.write_raw_data([row])\n",
    "    writer.commit()\n",
    "\n",
    "\n",
    "def create_maskrcnn_dataset(mindrecord_file, batch_size=2, device_num=1, rank_id=0,\n",
    "                            is_training=True, num_parallel_workers=2):\n",
    "    \"\"\"Create MaskRcnn dataset with MindDataset.\"\"\"\n",
    "    cv2.setNumThreads(0)\n",
    "    de.config.set_prefetch_size(8)\n",
    "    ds = de.MindDataset(mindrecord_file, columns_list=[\"image\", \"annotation\", \"mask\", \"mask_shape\"],\n",
    "                        num_shards=device_num, shard_id=rank_id,\n",
    "                        num_parallel_workers=4, shuffle=is_training)\n",
    "\n",
    "    decode = vision.Decode()\n",
    "    ds = ds.map(operations=decode, input_columns=[\"image\"])\n",
    "    compose_map_func = (lambda image, annotation, mask, mask_shape:\n",
    "                        preprocess_fn(image, annotation, mask, mask_shape, is_training))\n",
    "\n",
    "    if is_training:\n",
    "        ds = ds.map(operations=compose_map_func,\n",
    "                    input_columns=[\"image\", \"annotation\", \"mask\", \"mask_shape\"],\n",
    "                    output_columns=[\"image\", \"image_shape\", \"box\", \"label\", \"valid_num\", \"mask\"],\n",
    "                    column_order=[\"image\", \"image_shape\", \"box\", \"label\", \"valid_num\", \"mask\"],\n",
    "                    python_multiprocessing=False,\n",
    "                    num_parallel_workers=num_parallel_workers)\n",
    "        ds = ds.batch(batch_size, drop_remainder=True, pad_info={\"mask\": ([config.max_instance_count, None, None], 0)})\n",
    "\n",
    "    else:\n",
    "        ds = ds.map(operations=compose_map_func,\n",
    "                    input_columns=[\"image\", \"annotation\", \"mask\", \"mask_shape\"],\n",
    "                    output_columns=[\"image\", \"image_shape\", \"box\", \"label\", \"valid_num\", \"mask\"],\n",
    "                    column_order=[\"image\", \"image_shape\", \"box\", \"label\", \"valid_num\", \"mask\"],\n",
    "                    num_parallel_workers=num_parallel_workers)\n",
    "        ds = ds.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def create_mindrecord_dir(prefix, mindrecord_dir, mindrecord_file):\n",
    "    if not os.path.isdir(mindrecord_dir):\n",
    "        os.makedirs(mindrecord_dir)\n",
    "    if os.path.isdir('val2017'):\n",
    "        print(\"Create Mindrecord.\")\n",
    "        data_to_mindrecord_byte_image(\"coco\", True, prefix)\n",
    "        print(\"Create Mindrecord Done, at {}\".format(mindrecord_dir))\n",
    "    else:\n",
    "        raise Exception(\"coco_root not exits.\")\n",
    "    while not os.path.exists(mindrecord_file + \".db\"):\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c7bed9",
   "metadata": {},
   "source": [
    "## 模型构建\n",
    "本案例实现的Mask R-CNN结构和论文中的结构大体相同，骨干网络采用的是ResNet50。具体的网络结构，读者根据模型结构介绍中的图片以及论文原文中提供的mask分支结构可以有个清晰的认知，此处就不放具体的网络结构图了。\n",
    "\n",
    "在具体的实现上，MindSpore和pytorch差异不大，只是一些方法名上的替换，具体的API映射可见https://www.mindspore.cn/docs/zh-CN/r1.8/note/api_mapping/pytorch_api_mapping.html#torch-nn。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51a9f921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.22s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ResNet(nn.Cell):\n",
    "    \"\"\"\n",
    "    ResNet architecture.\n",
    "\n",
    "    Args:\n",
    "        block (Cell): Block for network.\n",
    "        layer_nums (list): Numbers of block in different layers.\n",
    "        in_channels (list): Input channel in each layer.\n",
    "        out_channels (list): Output channel in each layer.\n",
    "        weights_update (bool): Weight update flag.\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "\n",
    "    Examples:\n",
    "        >>> ResNet(ResidualBlock,\n",
    "        >>>        [3, 4, 6, 3],\n",
    "        >>>        [64, 256, 512, 1024],\n",
    "        >>>        [256, 512, 1024, 2048],\n",
    "        >>>        False)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 block,\n",
    "                 layer_nums,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 weights_update=False):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        if not len(layer_nums) == len(in_channels) == len(out_channels) == 4:\n",
    "            raise ValueError(\"the length of \"\n",
    "                             \"layer_num, inchannel, outchannel list must be 4!\")\n",
    "\n",
    "        bn_training = False\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, pad_mode='pad')\n",
    "        self.bn1 = nn.BatchNorm2d(64, affine=bn_training, use_batch_statistics=bn_training)\n",
    "        self.relu = P.ReLU()\n",
    "        self.maxpool = P.MaxPool(kernel_size=3, strides=2, pad_mode=\"SAME\")\n",
    "        self.weights_update = weights_update\n",
    "\n",
    "        if not self.weights_update:\n",
    "            self.conv1.weight.requires_grad = False\n",
    "\n",
    "        self.layer1 = self._make_layer(block,\n",
    "                                       layer_nums[0],\n",
    "                                       in_channel=in_channels[0],\n",
    "                                       out_channel=out_channels[0],\n",
    "                                       stride=1,\n",
    "                                       training=bn_training,\n",
    "                                       weights_update=self.weights_update)\n",
    "        self.layer2 = self._make_layer(block,\n",
    "                                       layer_nums[1],\n",
    "                                       in_channel=in_channels[1],\n",
    "                                       out_channel=out_channels[1],\n",
    "                                       stride=2,\n",
    "                                       training=bn_training,\n",
    "                                       weights_update=True)\n",
    "        self.layer3 = self._make_layer(block,\n",
    "                                       layer_nums[2],\n",
    "                                       in_channel=in_channels[2],\n",
    "                                       out_channel=out_channels[2],\n",
    "                                       stride=2,\n",
    "                                       training=bn_training,\n",
    "                                       weights_update=True)\n",
    "        self.layer4 = self._make_layer(block,\n",
    "                                       layer_nums[3],\n",
    "                                       in_channel=in_channels[3],\n",
    "                                       out_channel=out_channels[3],\n",
    "                                       stride=2,\n",
    "                                       training=bn_training,\n",
    "                                       weights_update=True)\n",
    "\n",
    "    def _make_layer(self, block, layer_num, in_channel, out_channel, stride, training=False, weights_update=False):\n",
    "        \"\"\"Make block layer.\"\"\"\n",
    "        layers = []\n",
    "        down_sample = False\n",
    "        if stride != 1 or in_channel != out_channel:\n",
    "            down_sample = True\n",
    "        resblk = block(in_channel,\n",
    "                       out_channel,\n",
    "                       stride=stride,\n",
    "                       down_sample=down_sample,\n",
    "                       training=training,\n",
    "                       weights_update=weights_update)\n",
    "        layers.append(resblk)\n",
    "\n",
    "        for _ in range(1, layer_num):\n",
    "            resblk = block(out_channel, out_channel, stride=1, training=training, weights_update=weights_update)\n",
    "            layers.append(resblk)\n",
    "\n",
    "        return nn.SequentialCell(layers)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        c1 = self.maxpool(x)\n",
    "\n",
    "        c2 = self.layer1(c1)\n",
    "        identity = c2\n",
    "        if not self.weights_update:\n",
    "            identity = F.stop_gradient(c2)\n",
    "        c3 = self.layer2(identity)\n",
    "        c4 = self.layer3(c3)\n",
    "        c5 = self.layer4(c4)\n",
    "\n",
    "        return identity, c3, c4, c5\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Cell):\n",
    "    \"\"\"\n",
    "    ResNet V1 residual block definition.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int) - Input channel.\n",
    "        out_channels (int) - Output channel.\n",
    "        stride (int) - Stride size for the initial convolutional layer. Default: 1.\n",
    "        down_sample (bool) - If to do the downsample in block. Default: False.\n",
    "        momentum (float) - Momentum for batchnorm layer. Default: 0.1.\n",
    "        training (bool) - Training flag. Default: False.\n",
    "        weights_updata (bool) - Weights update flag. Default: False.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "\n",
    "    Examples:\n",
    "        ResidualBlock(3,256,stride=2,down_sample=True)\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 stride=1,\n",
    "                 down_sample=False,\n",
    "                 momentum=0.1,\n",
    "                 training=False,\n",
    "                 weights_update=False):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.affine = weights_update\n",
    "\n",
    "        out_chls = out_channels // self.expansion\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_chls, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(out_chls, momentum=momentum, affine=self.affine, use_batch_statistics=training)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_chls, out_chls, kernel_size=3, stride=stride, pad_mode='pad', padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_chls, momentum=momentum, affine=self.affine, use_batch_statistics=training)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(out_chls, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels, momentum=momentum, affine=self.affine, use_batch_statistics=training)\n",
    "\n",
    "        if training:\n",
    "            self.bn1 = self.bn1.set_train()\n",
    "            self.bn2 = self.bn2.set_train()\n",
    "            self.bn3 = self.bn3.set_train()\n",
    "\n",
    "        if not weights_update:\n",
    "            self.conv1.weight.requires_grad = False\n",
    "            self.conv2.weight.requires_grad = False\n",
    "            self.conv3.weight.requires_grad = False\n",
    "\n",
    "        self.relu = P.ReLU()\n",
    "        self.downsample = down_sample\n",
    "        if self.downsample:\n",
    "            self.conv_down_sample = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0)\n",
    "            self.bn_down_sample = nn.BatchNorm2d(out_channels, momentum=momentum, affine=self.affine,\n",
    "                                                 use_batch_statistics=training)\n",
    "            if training:\n",
    "                self.bn_down_sample = self.bn_down_sample.set_train()\n",
    "            if not weights_update:\n",
    "                self.conv_down_sample.weight.requires_grad = False\n",
    "        self.add = P.Add()\n",
    "\n",
    "    def construct(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample:\n",
    "            identity = self.conv_down_sample(identity)\n",
    "            identity = self.bn_down_sample(identity)\n",
    "\n",
    "        out = self.add(out, identity)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class FeatPyramidNeck(nn.Cell):\n",
    "    \"\"\"\n",
    "    Feature pyramid network cell, usually uses as network neck.\n",
    "\n",
    "    Applies the convolution on multiple, input feature maps\n",
    "    and output feature map with same channel size. if required num of\n",
    "    output larger then num of inputs, add extra maxpooling for further\n",
    "    downsampling;\n",
    "\n",
    "    Args:\n",
    "        in_channels (tuple) - Channel size of input feature maps.\n",
    "        out_channels (int) - Channel size output.\n",
    "        num_outs (int) - Num of output features.\n",
    "\n",
    "    Returns:\n",
    "        Tuple, with tensors of same channel size.\n",
    "\n",
    "    Examples:\n",
    "        neck = FeatPyramidNeck([100,200,300], 50, 4, config.feature_shapes)\n",
    "        input_data = (normal(0,0.1,(1,c,1280//(4*2**i), 768//(4*2**i)),\n",
    "                      dtype=np.float32) \\\n",
    "                      for i, c in enumerate(config.fpn_in_channels))\n",
    "        x = neck(input_data)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 num_outs,\n",
    "                 feature_shapes):\n",
    "        super(FeatPyramidNeck, self).__init__()\n",
    "\n",
    "        if context.get_context(\"device_target\") == \"Ascend\":\n",
    "            self.cast_type = mstype.float32\n",
    "        else:\n",
    "            self.cast_type = mstype.float32\n",
    "\n",
    "        self.num_outs = num_outs\n",
    "        self.in_channels = in_channels\n",
    "        self.fpn_layer = len(self.in_channels)\n",
    "\n",
    "        assert not self.num_outs < len(in_channels)\n",
    "\n",
    "        self.lateral_convs_list_ = []\n",
    "        self.fpn_convs_ = []\n",
    "\n",
    "        for _, channel in enumerate(in_channels):\n",
    "            l_conv = nn.Conv2d(channel, out_channels, kernel_size=1, stride=1,\n",
    "                               padding=0, pad_mode='valid').to_float(self.cast_type)\n",
    "            fpn_conv = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1,\n",
    "                                 padding=0, pad_mode='same').to_float(self.cast_type)\n",
    "            self.lateral_convs_list_.append(l_conv)\n",
    "            self.fpn_convs_.append(fpn_conv)\n",
    "        self.lateral_convs_list = nn.layer.CellList(self.lateral_convs_list_)\n",
    "        self.fpn_convs_list = nn.layer.CellList(self.fpn_convs_)\n",
    "        self.interpolate1 = P.ResizeBilinear(feature_shapes[2])\n",
    "        self.interpolate2 = P.ResizeBilinear(feature_shapes[1])\n",
    "        self.interpolate3 = P.ResizeBilinear(feature_shapes[0])\n",
    "        self.cast = P.Cast()\n",
    "        self.maxpool = P.MaxPool(kernel_size=1, strides=2, pad_mode=\"same\")\n",
    "\n",
    "    def construct(self, inputs):\n",
    "        x = ()\n",
    "        for i in range(self.fpn_layer):\n",
    "            x += (self.lateral_convs_list[i](inputs[i]),)\n",
    "\n",
    "        y = (x[3],)\n",
    "        y = y + (x[2] + self.cast(self.interpolate1(y[self.fpn_layer - 4]), self.cast_type),)\n",
    "        y = y + (x[1] + self.cast(self.interpolate2(y[self.fpn_layer - 3]), self.cast_type),)\n",
    "        y = y + (x[0] + self.cast(self.interpolate3(y[self.fpn_layer - 2]), self.cast_type),)\n",
    "\n",
    "        z = ()\n",
    "        for i in range(self.fpn_layer - 1, -1, -1):\n",
    "            z = z + (y[i],)\n",
    "\n",
    "        outs = ()\n",
    "        for i in range(self.fpn_layer):\n",
    "            outs = outs + (self.fpn_convs_list[i](z[i]),)\n",
    "\n",
    "        for i in range(self.num_outs - self.fpn_layer):\n",
    "            outs = outs + (self.maxpool(outs[3]),)\n",
    "        return outs\n",
    "\n",
    "\n",
    "class BboxAssignSample(nn.Cell):\n",
    "    \"\"\"\n",
    "    Bbox assigner and sampler definition.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Config.\n",
    "        batch_size (int): Batchsize.\n",
    "        num_bboxes (int): The anchor nums.\n",
    "        add_gt_as_proposals (bool): add gt bboxes as proposals flag.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "        bbox_targets: bbox location, (batch_size, num_bboxes, 4)\n",
    "        bbox_weights: bbox weights, (batch_size, num_bboxes, 1)\n",
    "        labels: label for every bboxes, (batch_size, num_bboxes, 1)\n",
    "        label_weights: label weight for every bboxes, (batch_size, num_bboxes, 1)\n",
    "\n",
    "    Examples:\n",
    "        BboxAssignSample(config, 2, 1024, True)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, batch_size, num_bboxes, add_gt_as_proposals):\n",
    "        super(BboxAssignSample, self).__init__()\n",
    "        cfg = config\n",
    "\n",
    "        if context.get_context(\"device_target\") == \"Ascend\":\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "        else:\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.neg_iou_thr = Tensor(cfg.neg_iou_thr, self.cast_type)\n",
    "        self.pos_iou_thr = Tensor(cfg.pos_iou_thr, self.cast_type)\n",
    "        self.min_pos_iou = Tensor(cfg.min_pos_iou, self.cast_type)\n",
    "        self.zero_thr = Tensor(0.0, self.cast_type)\n",
    "\n",
    "        self.num_bboxes = num_bboxes\n",
    "        self.num_gts = cfg.num_gts\n",
    "        self.num_expected_pos = cfg.num_expected_pos\n",
    "        self.num_expected_neg = cfg.num_expected_neg\n",
    "        self.add_gt_as_proposals = add_gt_as_proposals\n",
    "\n",
    "        if self.add_gt_as_proposals:\n",
    "            self.label_inds = Tensor(np.arange(1, self.num_gts + 1))\n",
    "\n",
    "        self.concat = P.Concat(axis=0)\n",
    "        self.max_gt = P.ArgMaxWithValue(axis=0)\n",
    "        self.max_anchor = P.ArgMaxWithValue(axis=1)\n",
    "        self.sum_inds = P.ReduceSum()\n",
    "        self.iou = P.IOU()\n",
    "        self.greaterequal = P.GreaterEqual()\n",
    "        self.greater = P.Greater()\n",
    "        self.select = P.Select()\n",
    "        self.gatherND = P.GatherNd()\n",
    "        self.squeeze = P.Squeeze()\n",
    "        self.cast = P.Cast()\n",
    "        self.logicaland = P.LogicalAnd()\n",
    "        self.less = P.Less()\n",
    "        self.random_choice_with_mask_pos = P.RandomChoiceWithMask(self.num_expected_pos)\n",
    "        self.random_choice_with_mask_neg = P.RandomChoiceWithMask(self.num_expected_neg)\n",
    "        self.reshape = P.Reshape()\n",
    "        self.equal = P.Equal()\n",
    "        self.bounding_box_encode = P.BoundingBoxEncode(means=(0.0, 0.0, 0.0, 0.0), stds=(1.0, 1.0, 1.0, 1.0))\n",
    "        self.scatterNdUpdate = P.ScatterNdUpdate()\n",
    "        self.scatterNd = P.ScatterNd()\n",
    "        self.logicalnot = P.LogicalNot()\n",
    "        self.tile = P.Tile()\n",
    "        self.zeros_like = P.ZerosLike()\n",
    "\n",
    "        self.assigned_gt_inds = Tensor(np.array(-1 * np.ones(num_bboxes), dtype=np.int32))\n",
    "        self.assigned_gt_zeros = Tensor(np.array(np.zeros(num_bboxes), dtype=np.int32))\n",
    "        self.assigned_gt_ones = Tensor(np.array(np.ones(num_bboxes), dtype=np.int32))\n",
    "        self.assigned_gt_ignores = Tensor(np.array(-1 * np.ones(num_bboxes), dtype=np.int32))\n",
    "        self.assigned_pos_ones = Tensor(np.array(np.ones(self.num_expected_pos), dtype=np.int32))\n",
    "\n",
    "        self.check_neg_mask = Tensor(np.array(np.ones(self.num_expected_neg - self.num_expected_pos), dtype=bool))\n",
    "        self.range_pos_size = Tensor(np.arange(self.num_expected_pos).astype(self.np_cast_type))\n",
    "        self.check_gt_one = Tensor(np.array(-1 * np.ones((self.num_gts, 4)), dtype=self.np_cast_type))\n",
    "        self.check_anchor_two = Tensor(np.array(-2 * np.ones((self.num_bboxes, 4)), dtype=self.np_cast_type))\n",
    "\n",
    "    def construct(self, gt_bboxes_i, gt_labels_i, valid_mask, bboxes, gt_valids):\n",
    "        gt_bboxes_i = self.select(self.cast(self.tile(self.reshape(self.cast(gt_valids, mstype.int32), \\\n",
    "                                                                   (self.num_gts, 1)), (1, 4)), mstype.bool_),\n",
    "                                  gt_bboxes_i, self.check_gt_one)\n",
    "        bboxes = self.select(self.cast(self.tile(self.reshape(self.cast(valid_mask, mstype.int32), \\\n",
    "                                                              (self.num_bboxes, 1)), (1, 4)), mstype.bool_), bboxes,\n",
    "                             self.check_anchor_two)\n",
    "\n",
    "        overlaps = self.iou(bboxes, gt_bboxes_i)\n",
    "\n",
    "        max_overlaps_w_gt_index, max_overlaps_w_gt = self.max_gt(overlaps)\n",
    "        _, max_overlaps_w_ac = self.max_anchor(overlaps)\n",
    "\n",
    "        neg_sample_iou_mask = self.logicaland(self.greaterequal(max_overlaps_w_gt, self.zero_thr), \\\n",
    "                                              self.less(max_overlaps_w_gt, self.neg_iou_thr))\n",
    "        assigned_gt_inds2 = self.select(neg_sample_iou_mask, self.assigned_gt_zeros, self.assigned_gt_inds)\n",
    "\n",
    "        pos_sample_iou_mask = self.greaterequal(max_overlaps_w_gt, self.pos_iou_thr)\n",
    "        assigned_gt_inds3 = self.select(pos_sample_iou_mask, \\\n",
    "                                        max_overlaps_w_gt_index + self.assigned_gt_ones, assigned_gt_inds2)\n",
    "        assigned_gt_inds4 = assigned_gt_inds3\n",
    "        for j in range(self.num_gts):\n",
    "            max_overlaps_w_ac_j = max_overlaps_w_ac[j:j + 1:1]\n",
    "            overlaps_w_gt_j = self.squeeze(overlaps[j:j + 1:1, ::])\n",
    "\n",
    "            pos_mask_j = self.logicaland(self.greaterequal(max_overlaps_w_ac_j, self.min_pos_iou), \\\n",
    "                                         self.equal(overlaps_w_gt_j, max_overlaps_w_ac_j))\n",
    "\n",
    "            assigned_gt_inds4 = self.select(pos_mask_j, self.assigned_gt_ones + j, assigned_gt_inds4)\n",
    "\n",
    "        assigned_gt_inds5 = self.select(valid_mask, assigned_gt_inds4, self.assigned_gt_ignores)\n",
    "\n",
    "        pos_index, valid_pos_index = self.random_choice_with_mask_pos(self.greater(assigned_gt_inds5, 0))\n",
    "\n",
    "        pos_check_valid = self.cast(self.greater(assigned_gt_inds5, 0), self.cast_type)\n",
    "        pos_check_valid = self.sum_inds(pos_check_valid, -1)\n",
    "        valid_pos_index = self.less(self.range_pos_size, pos_check_valid)\n",
    "        pos_index = pos_index * self.reshape(self.cast(valid_pos_index, mstype.int32), (self.num_expected_pos, 1))\n",
    "\n",
    "        pos_assigned_gt_index = self.gatherND(assigned_gt_inds5, pos_index) - self.assigned_pos_ones\n",
    "        pos_assigned_gt_index = pos_assigned_gt_index * self.cast(valid_pos_index, mstype.int32)\n",
    "        pos_assigned_gt_index = self.reshape(pos_assigned_gt_index, (self.num_expected_pos, 1))\n",
    "\n",
    "        neg_index, valid_neg_index = self.random_choice_with_mask_neg(self.equal(assigned_gt_inds5, 0))\n",
    "\n",
    "        num_pos = self.cast(self.logicalnot(valid_pos_index), self.cast_type)\n",
    "        num_pos = self.sum_inds(num_pos, -1)\n",
    "        unvalid_pos_index = self.less(self.range_pos_size, num_pos)\n",
    "        valid_neg_index = self.logicaland(self.concat((self.check_neg_mask, unvalid_pos_index)), valid_neg_index)\n",
    "\n",
    "        pos_bboxes_ = self.gatherND(bboxes, pos_index)\n",
    "        pos_gt_bboxes_ = self.gatherND(gt_bboxes_i, pos_assigned_gt_index)\n",
    "        pos_gt_labels = self.gatherND(gt_labels_i, pos_assigned_gt_index)\n",
    "\n",
    "        pos_bbox_targets_ = self.bounding_box_encode(pos_bboxes_, pos_gt_bboxes_)\n",
    "\n",
    "        valid_pos_index = self.cast(valid_pos_index, mstype.int32)\n",
    "        valid_neg_index = self.cast(valid_neg_index, mstype.int32)\n",
    "        bbox_targets_total = self.scatterNd(pos_index, pos_bbox_targets_, (self.num_bboxes, 4))\n",
    "        bbox_weights_total = self.scatterNd(pos_index, valid_pos_index, (self.num_bboxes,))\n",
    "        labels_total = self.scatterNd(pos_index, pos_gt_labels, (self.num_bboxes,))\n",
    "        total_index = self.concat((pos_index, neg_index))\n",
    "        total_valid_index = self.concat((valid_pos_index, valid_neg_index))\n",
    "        label_weights_total = self.scatterNd(total_index, total_valid_index, (self.num_bboxes,))\n",
    "\n",
    "        return bbox_targets_total, self.cast(bbox_weights_total, mstype.bool_), \\\n",
    "               labels_total, self.cast(label_weights_total, mstype.bool_)\n",
    "\n",
    "\n",
    "class RpnRegClsBlock(nn.Cell):\n",
    "    \"\"\"\n",
    "    Rpn reg cls block for rpn layer\n",
    "\n",
    "    Args:\n",
    "        in_channels (int) - Input channels of shared convolution.\n",
    "        feat_channels (int) - Output channels of shared convolution.\n",
    "        num_anchors (int) - The anchor number.\n",
    "        cls_out_channels (int) - Output channels of classification convolution.\n",
    "        weight_conv (Tensor) - weight init for rpn conv.\n",
    "        bias_conv (Tensor) - bias init for rpn conv.\n",
    "        weight_cls (Tensor) - weight init for rpn cls conv.\n",
    "        bias_cls (Tensor) - bias init for rpn cls conv.\n",
    "        weight_reg (Tensor) - weight init for rpn reg conv.\n",
    "        bias_reg (Tensor) - bias init for rpn reg conv.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 feat_channels,\n",
    "                 num_anchors,\n",
    "                 cls_out_channels,\n",
    "                 weight_conv,\n",
    "                 bias_conv,\n",
    "                 weight_cls,\n",
    "                 bias_cls,\n",
    "                 weight_reg,\n",
    "                 bias_reg):\n",
    "        super(RpnRegClsBlock, self).__init__()\n",
    "        self.rpn_conv = nn.Conv2d(in_channels, feat_channels, kernel_size=3, stride=1, pad_mode='same',\n",
    "                                  has_bias=True, weight_init=weight_conv, bias_init=bias_conv)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.rpn_cls = nn.Conv2d(feat_channels, num_anchors * cls_out_channels, kernel_size=1, pad_mode='valid',\n",
    "                                 has_bias=True, weight_init=weight_cls, bias_init=bias_cls)\n",
    "        self.rpn_reg = nn.Conv2d(feat_channels, num_anchors * 4, kernel_size=1, pad_mode='valid',\n",
    "                                 has_bias=True, weight_init=weight_reg, bias_init=bias_reg)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.relu(self.rpn_conv(x))\n",
    "\n",
    "        x1 = self.rpn_cls(x)\n",
    "        x2 = self.rpn_reg(x)\n",
    "\n",
    "        return x1, x2\n",
    "\n",
    "\n",
    "class RPN(nn.Cell):\n",
    "    \"\"\"\n",
    "    ROI proposal network..\n",
    "\n",
    "    Args:\n",
    "        config (dict) - Config.\n",
    "        batch_size (int) - Batchsize.\n",
    "        in_channels (int) - Input channels of shared convolution.\n",
    "        feat_channels (int) - Output channels of shared convolution.\n",
    "        num_anchors (int) - The anchor number.\n",
    "        cls_out_channels (int) - Output channels of classification convolution.\n",
    "\n",
    "    Returns:\n",
    "        Tuple, tuple of output tensor.\n",
    "\n",
    "    Examples:\n",
    "        RPN(config=config, batch_size=2, in_channels=256, feat_channels=1024,\n",
    "            num_anchors=3, cls_out_channels=512)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 config,\n",
    "                 batch_size,\n",
    "                 in_channels,\n",
    "                 feat_channels,\n",
    "                 num_anchors,\n",
    "                 cls_out_channels):\n",
    "        super(RPN, self).__init__()\n",
    "        cfg_rpn = config\n",
    "        if context.get_context(\"device_target\") == \"CPU\" or context.get_context(\"device_target\") == \"GPU\":\n",
    "            self.platform_dtype = np.float32\n",
    "            self.platform_mstype = mstype.float32\n",
    "        else:\n",
    "            self.platform_dtype = np.float32\n",
    "            self.platform_mstype = mstype.float32\n",
    "        self.num_bboxes = cfg_rpn.num_bboxes\n",
    "        self.slice_index = ()\n",
    "        self.feature_anchor_shape = ()\n",
    "        self.slice_index += (0,)\n",
    "        index = 0\n",
    "        for shape in cfg_rpn.feature_shapes:\n",
    "            self.slice_index += (self.slice_index[index] + shape[0] * shape[1] * num_anchors,)\n",
    "            self.feature_anchor_shape += (shape[0] * shape[1] * num_anchors * batch_size,)\n",
    "            index += 1\n",
    "\n",
    "        self.num_anchors = num_anchors\n",
    "        self.batch_size = batch_size\n",
    "        self.test_batch_size = cfg_rpn.test_batch_size\n",
    "        self.num_layers = 5\n",
    "        self.real_ratio = Tensor(np.ones((1, 1)).astype(self.platform_dtype))\n",
    "\n",
    "        self.rpn_convs_list = nn.layer.CellList(self._make_rpn_layer(self.num_layers, in_channels, feat_channels,\n",
    "                                                                     num_anchors, cls_out_channels))\n",
    "\n",
    "        self.transpose = P.Transpose()\n",
    "        self.reshape = P.Reshape()\n",
    "        self.concat = P.Concat(axis=0)\n",
    "        self.fill = P.Fill()\n",
    "        self.placeh1 = Tensor(np.ones((1,)).astype(self.platform_dtype))\n",
    "\n",
    "        self.trans_shape = (0, 2, 3, 1)\n",
    "\n",
    "        self.reshape_shape_reg = (-1, 4)\n",
    "        self.reshape_shape_cls = (-1,)\n",
    "        self.rpn_loss_reg_weight = Tensor(np.array(cfg_rpn.rpn_loss_reg_weight).astype(self.platform_dtype))\n",
    "        self.rpn_loss_cls_weight = Tensor(np.array(cfg_rpn.rpn_loss_cls_weight).astype(self.platform_dtype))\n",
    "        self.num_expected_total = Tensor(np.array(cfg_rpn.num_expected_neg * \\\n",
    "                                                  self.batch_size).astype(self.platform_dtype))\n",
    "        self.num_bboxes = cfg_rpn.num_bboxes\n",
    "        self.get_targets = BboxAssignSample(cfg_rpn, self.batch_size, self.num_bboxes, False)\n",
    "        self.CheckValid = P.CheckValid()\n",
    "        self.sum_loss = P.ReduceSum()\n",
    "        self.loss_cls = P.SigmoidCrossEntropyWithLogits()\n",
    "        self.loss_bbox = P.SmoothL1Loss(beta=1.0/9.0)\n",
    "        self.squeeze = P.Squeeze()\n",
    "        self.cast = P.Cast()\n",
    "        self.tile = P.Tile()\n",
    "        self.zeros_like = P.ZerosLike()\n",
    "        self.loss = Tensor(np.zeros((1,)).astype(self.platform_dtype))\n",
    "        self.clsloss = Tensor(np.zeros((1,)).astype(self.platform_dtype))\n",
    "        self.regloss = Tensor(np.zeros((1,)).astype(self.platform_dtype))\n",
    "\n",
    "    def _make_rpn_layer(self, num_layers, in_channels, feat_channels, num_anchors, cls_out_channels):\n",
    "        \"\"\"\n",
    "        make rpn layer for rpn proposal network\n",
    "\n",
    "        Args:\n",
    "        num_layers (int) - layer num.\n",
    "        in_channels (int) - Input channels of shared convolution.\n",
    "        feat_channels (int) - Output channels of shared convolution.\n",
    "        num_anchors (int) - The anchor number.\n",
    "        cls_out_channels (int) - Output channels of classification convolution.\n",
    "\n",
    "        Returns:\n",
    "        List, list of RpnRegClsBlock cells.\n",
    "        \"\"\"\n",
    "        rpn_layer = []\n",
    "\n",
    "        shp_weight_conv = (feat_channels, in_channels, 3, 3)\n",
    "        shp_bias_conv = (feat_channels,)\n",
    "        weight_conv = initializer('Normal', shape=shp_weight_conv, dtype=mstype.float32)\n",
    "        bias_conv = initializer(0, shape=shp_bias_conv, dtype=mstype.float32)\n",
    "\n",
    "        shp_weight_cls = (num_anchors * cls_out_channels, feat_channels, 1, 1)\n",
    "        shp_bias_cls = (num_anchors * cls_out_channels,)\n",
    "        weight_cls = initializer('Normal', shape=shp_weight_cls, dtype=mstype.float32)\n",
    "        bias_cls = initializer(0, shape=shp_bias_cls, dtype=mstype.float32)\n",
    "\n",
    "        shp_weight_reg = (num_anchors * 4, feat_channels, 1, 1)\n",
    "        shp_bias_reg = (num_anchors * 4,)\n",
    "        weight_reg = initializer('Normal', shape=shp_weight_reg, dtype=mstype.float32)\n",
    "        bias_reg = initializer(0, shape=shp_bias_reg, dtype=mstype.float32)\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            rpn_layer.append(RpnRegClsBlock(in_channels, feat_channels, num_anchors, cls_out_channels, \\\n",
    "                                            weight_conv, bias_conv, weight_cls, \\\n",
    "                                            bias_cls, weight_reg, bias_reg).to_float(self.platform_mstype))\n",
    "\n",
    "        for i in range(1, num_layers):\n",
    "            rpn_layer[i].rpn_conv.weight = rpn_layer[0].rpn_conv.weight\n",
    "            rpn_layer[i].rpn_cls.weight = rpn_layer[0].rpn_cls.weight\n",
    "            rpn_layer[i].rpn_reg.weight = rpn_layer[0].rpn_reg.weight\n",
    "\n",
    "            rpn_layer[i].rpn_conv.bias = rpn_layer[0].rpn_conv.bias\n",
    "            rpn_layer[i].rpn_cls.bias = rpn_layer[0].rpn_cls.bias\n",
    "            rpn_layer[i].rpn_reg.bias = rpn_layer[0].rpn_reg.bias\n",
    "\n",
    "        return rpn_layer\n",
    "\n",
    "    def construct(self, inputs, img_metas, anchor_list, gt_bboxes, gt_labels, gt_valids):\n",
    "        loss_print = ()\n",
    "        rpn_cls_score = ()\n",
    "        rpn_bbox_pred = ()\n",
    "        rpn_cls_score_total = ()\n",
    "        rpn_bbox_pred_total = ()\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x1, x2 = self.rpn_convs_list[i](inputs[i])\n",
    "\n",
    "            rpn_cls_score_total = rpn_cls_score_total + (x1,)\n",
    "            rpn_bbox_pred_total = rpn_bbox_pred_total + (x2,)\n",
    "\n",
    "            x1 = self.transpose(x1, self.trans_shape)\n",
    "            x1 = self.reshape(x1, self.reshape_shape_cls)\n",
    "\n",
    "            x2 = self.transpose(x2, self.trans_shape)\n",
    "            x2 = self.reshape(x2, self.reshape_shape_reg)\n",
    "\n",
    "            rpn_cls_score = rpn_cls_score + (x1,)\n",
    "            rpn_bbox_pred = rpn_bbox_pred + (x2,)\n",
    "\n",
    "        loss = self.loss\n",
    "        clsloss = self.clsloss\n",
    "        regloss = self.regloss\n",
    "        bbox_targets = ()\n",
    "        bbox_weights = ()\n",
    "        labels = ()\n",
    "        label_weights = ()\n",
    "\n",
    "        output = ()\n",
    "        if self.training:\n",
    "            for i in range(self.batch_size):\n",
    "                multi_level_flags = ()\n",
    "                anchor_list_tuple = ()\n",
    "\n",
    "                for j in range(self.num_layers):\n",
    "                    res = self.cast(self.CheckValid(anchor_list[j], self.squeeze(img_metas[i:i + 1, ::])),\n",
    "                                    mstype.int32)\n",
    "                    multi_level_flags = multi_level_flags + (res,)\n",
    "                    anchor_list_tuple = anchor_list_tuple + (anchor_list[j],)\n",
    "\n",
    "                valid_flag_list = self.concat(multi_level_flags)\n",
    "                anchor_using_list = self.concat(anchor_list_tuple)\n",
    "\n",
    "                gt_bboxes_i = self.squeeze(gt_bboxes[i:i + 1:1, ::])\n",
    "                gt_labels_i = self.squeeze(gt_labels[i:i + 1:1, ::])\n",
    "                gt_valids_i = self.squeeze(gt_valids[i:i + 1:1, ::])\n",
    "\n",
    "                bbox_target, bbox_weight, label, label_weight = self.get_targets(gt_bboxes_i,\n",
    "                                                                                 gt_labels_i,\n",
    "                                                                                 self.cast(valid_flag_list,\n",
    "                                                                                           mstype.bool_),\n",
    "                                                                                 anchor_using_list, gt_valids_i)\n",
    "\n",
    "                bbox_weight = self.cast(bbox_weight, self.platform_mstype)\n",
    "                label = self.cast(label, self.platform_mstype)\n",
    "                label_weight = self.cast(label_weight, self.platform_mstype)\n",
    "\n",
    "                for j in range(self.num_layers):\n",
    "                    begin = self.slice_index[j]\n",
    "                    end = self.slice_index[j + 1]\n",
    "                    stride = 1\n",
    "                    bbox_targets += (bbox_target[begin:end:stride, ::],)\n",
    "                    bbox_weights += (bbox_weight[begin:end:stride],)\n",
    "                    labels += (label[begin:end:stride],)\n",
    "                    label_weights += (label_weight[begin:end:stride],)\n",
    "\n",
    "            for i in range(self.num_layers):\n",
    "                bbox_target_using = ()\n",
    "                bbox_weight_using = ()\n",
    "                label_using = ()\n",
    "                label_weight_using = ()\n",
    "\n",
    "                for j in range(self.batch_size):\n",
    "                    bbox_target_using += (bbox_targets[i + (self.num_layers * j)],)\n",
    "                    bbox_weight_using += (bbox_weights[i + (self.num_layers * j)],)\n",
    "                    label_using += (labels[i + (self.num_layers * j)],)\n",
    "                    label_weight_using += (label_weights[i + (self.num_layers * j)],)\n",
    "\n",
    "                bbox_target_with_batchsize = self.concat(bbox_target_using)\n",
    "                bbox_weight_with_batchsize = self.concat(bbox_weight_using)\n",
    "                label_with_batchsize = self.concat(label_using)\n",
    "                label_weight_with_batchsize = self.concat(label_weight_using)\n",
    "\n",
    "                # stop\n",
    "                bbox_target_ = F.stop_gradient(bbox_target_with_batchsize)\n",
    "                bbox_weight_ = F.stop_gradient(bbox_weight_with_batchsize)\n",
    "                label_ = F.stop_gradient(label_with_batchsize)\n",
    "                label_weight_ = F.stop_gradient(label_weight_with_batchsize)\n",
    "\n",
    "                cls_score_i = rpn_cls_score[i]\n",
    "                reg_score_i = rpn_bbox_pred[i]\n",
    "\n",
    "                loss_cls = self.loss_cls(cls_score_i, label_)\n",
    "                loss_cls_item = loss_cls * label_weight_\n",
    "                loss_cls_item = self.sum_loss(loss_cls_item, (0,)) / self.num_expected_total\n",
    "\n",
    "                loss_reg = self.loss_bbox(reg_score_i, bbox_target_)\n",
    "                bbox_weight_ = self.tile(self.reshape(bbox_weight_, (self.feature_anchor_shape[i], 1)), (1, 4))\n",
    "                loss_reg = loss_reg * bbox_weight_\n",
    "                loss_reg_item = self.sum_loss(loss_reg, (1,))\n",
    "                loss_reg_item = self.sum_loss(loss_reg_item, (0,)) / self.num_expected_total\n",
    "\n",
    "                loss_total = self.rpn_loss_cls_weight * loss_cls_item + self.rpn_loss_reg_weight * loss_reg_item\n",
    "\n",
    "                loss += loss_total\n",
    "                loss_print += (loss_total, loss_cls_item, loss_reg_item)\n",
    "                clsloss += loss_cls_item\n",
    "                regloss += loss_reg_item\n",
    "\n",
    "                output = (loss, rpn_cls_score_total, rpn_bbox_pred_total, clsloss, regloss, loss_print)\n",
    "        else:\n",
    "            output = (self.placeh1, rpn_cls_score_total, rpn_bbox_pred_total, self.placeh1, self.placeh1, self.placeh1)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class Proposal(nn.Cell):\n",
    "    \"\"\"\n",
    "    Proposal subnet.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Config.\n",
    "        batch_size (int): Batchsize.\n",
    "        num_classes (int) - Class number.\n",
    "        use_sigmoid_cls (bool) - Select sigmoid or softmax function.\n",
    "        target_means (tuple) - Means for encode function. Default: (.0, .0, .0, .0).\n",
    "        target_stds (tuple) - Stds for encode function. Default: (1.0, 1.0, 1.0, 1.0).\n",
    "\n",
    "    Returns:\n",
    "        Tuple, tuple of output tensor,(proposal, mask).\n",
    "\n",
    "    Examples:\n",
    "        Proposal(config = config, batch_size = 1, num_classes = 81, use_sigmoid_cls = True, \\\n",
    "                 target_means=(.0, .0, .0, .0), target_stds=(1.0, 1.0, 1.0, 1.0))\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 config,\n",
    "                 batch_size,\n",
    "                 num_classes,\n",
    "                 use_sigmoid_cls,\n",
    "                 target_means=(.0, .0, .0, .0),\n",
    "                 target_stds=(1.0, 1.0, 1.0, 1.0)\n",
    "                 ):\n",
    "        super(Proposal, self).__init__()\n",
    "        cfg = config\n",
    "\n",
    "        if context.get_context(\"device_target\") == \"Ascend\":\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "        else:\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = num_classes\n",
    "        self.target_means = target_means\n",
    "        self.target_stds = target_stds\n",
    "        self.use_sigmoid_cls = use_sigmoid_cls\n",
    "        self.reshape_shape = (-1, 1)\n",
    "\n",
    "        if self.use_sigmoid_cls:\n",
    "            self.cls_out_channels = num_classes - 1\n",
    "            self.activation = P.Sigmoid()\n",
    "        else:\n",
    "            self.cls_out_channels = num_classes\n",
    "            self.activation = P.Softmax(axis=1)\n",
    "\n",
    "        if self.cls_out_channels <= 0:\n",
    "            raise ValueError('num_classes={} is too small'.format(num_classes))\n",
    "\n",
    "        self.num_pre = cfg.rpn_proposal_nms_pre\n",
    "        self.min_box_size = cfg.rpn_proposal_min_bbox_size\n",
    "        self.nms_thr = cfg.rpn_proposal_nms_thr\n",
    "        self.nms_post = cfg.rpn_proposal_nms_post\n",
    "        self.nms_across_levels = cfg.rpn_proposal_nms_across_levels\n",
    "        self.max_num = cfg.rpn_proposal_max_num\n",
    "        self.num_levels = cfg.fpn_num_outs\n",
    "\n",
    "        # Op Define\n",
    "        self.squeeze = P.Squeeze()\n",
    "        self.reshape = P.Reshape()\n",
    "        self.cast = P.Cast()\n",
    "\n",
    "        self.feature_shapes = cfg.feature_shapes\n",
    "\n",
    "        self.transpose_shape = (1, 2, 0)\n",
    "\n",
    "        self.decode = P.BoundingBoxDecode(max_shape=(cfg.img_height, cfg.img_width), \\\n",
    "                                          means=self.target_means, \\\n",
    "                                          stds=self.target_stds)\n",
    "\n",
    "        self.nms = P.NMSWithMask(self.nms_thr)\n",
    "        self.concat_axis0 = P.Concat(axis=0)\n",
    "        self.concat_axis1 = P.Concat(axis=1)\n",
    "        self.split = P.Split(axis=1, output_num=5)\n",
    "        self.min = P.Minimum()\n",
    "        self.gatherND = P.GatherNd()\n",
    "        self.slice = P.Slice()\n",
    "        self.select = P.Select()\n",
    "        self.greater = P.Greater()\n",
    "        self.transpose = P.Transpose()\n",
    "        self.tile = P.Tile()\n",
    "        self.set_train_local(config, training=True)\n",
    "\n",
    "        self.multi_10 = Tensor(10.0, self.cast_type)\n",
    "\n",
    "    def set_train_local(self, config, training=True):\n",
    "        \"\"\"Set training flag.\"\"\"\n",
    "        self.training_local = training\n",
    "\n",
    "        cfg = config\n",
    "        self.topK_stage1 = ()\n",
    "        self.topK_shape = ()\n",
    "        total_max_topk_input = 0\n",
    "        if not self.training_local:\n",
    "            self.num_pre = cfg.rpn_nms_pre\n",
    "            self.min_box_size = cfg.rpn_min_bbox_min_size\n",
    "            self.nms_thr = cfg.rpn_nms_thr\n",
    "            self.nms_post = cfg.rpn_nms_post\n",
    "            self.nms_across_levels = cfg.rpn_nms_across_levels\n",
    "            self.max_num = cfg.rpn_max_num\n",
    "\n",
    "        for shp in self.feature_shapes:\n",
    "            k_num = min(self.num_pre, (shp[0] * shp[1] * 3))\n",
    "            total_max_topk_input += k_num\n",
    "            self.topK_stage1 += (k_num,)\n",
    "            self.topK_shape += ((k_num, 1),)\n",
    "\n",
    "        self.topKv2 = P.TopK(sorted=True)\n",
    "        self.topK_shape_stage2 = (self.max_num, 1)\n",
    "        self.min_float_num = -65536.0\n",
    "        self.topK_mask = Tensor(self.min_float_num * np.ones(total_max_topk_input, self.np_cast_type))\n",
    "\n",
    "    def construct(self, rpn_cls_score_total, rpn_bbox_pred_total, anchor_list):\n",
    "        proposals_tuple = ()\n",
    "        masks_tuple = ()\n",
    "        for img_id in range(self.batch_size):\n",
    "            cls_score_list = ()\n",
    "            bbox_pred_list = ()\n",
    "            for i in range(self.num_levels):\n",
    "                rpn_cls_score_i = self.squeeze(rpn_cls_score_total[i][img_id:img_id + 1:1, ::, ::, ::])\n",
    "                rpn_bbox_pred_i = self.squeeze(rpn_bbox_pred_total[i][img_id:img_id + 1:1, ::, ::, ::])\n",
    "\n",
    "                cls_score_list = cls_score_list + (rpn_cls_score_i,)\n",
    "                bbox_pred_list = bbox_pred_list + (rpn_bbox_pred_i,)\n",
    "\n",
    "            proposals, masks = self.get_bboxes_single(cls_score_list, bbox_pred_list, anchor_list)\n",
    "            proposals_tuple += (proposals,)\n",
    "            masks_tuple += (masks,)\n",
    "        return proposals_tuple, masks_tuple\n",
    "\n",
    "    def get_bboxes_single(self, cls_scores, bbox_preds, mlvl_anchors):\n",
    "        \"\"\"Get proposal boundingbox.\"\"\"\n",
    "        mlvl_proposals = ()\n",
    "        mlvl_mask = ()\n",
    "        for idx in range(self.num_levels):\n",
    "            rpn_cls_score = self.transpose(cls_scores[idx], self.transpose_shape)\n",
    "            rpn_bbox_pred = self.transpose(bbox_preds[idx], self.transpose_shape)\n",
    "            anchors = mlvl_anchors[idx]\n",
    "\n",
    "            rpn_cls_score = self.reshape(rpn_cls_score, self.reshape_shape)\n",
    "            rpn_cls_score = self.activation(rpn_cls_score)\n",
    "            rpn_cls_score_process = self.cast(self.squeeze(rpn_cls_score[::, 0::]), self.cast_type)\n",
    "\n",
    "            rpn_bbox_pred_process = self.cast(self.reshape(rpn_bbox_pred, (-1, 4)), self.cast_type)\n",
    "\n",
    "            scores_sorted, topk_inds = self.topKv2(rpn_cls_score_process, self.topK_stage1[idx])\n",
    "\n",
    "            topk_inds = self.reshape(topk_inds, self.topK_shape[idx])\n",
    "\n",
    "            bboxes_sorted = self.gatherND(rpn_bbox_pred_process, topk_inds)\n",
    "            anchors_sorted = self.cast(self.gatherND(anchors, topk_inds), self.cast_type)\n",
    "\n",
    "            proposals_decode = self.decode(anchors_sorted, bboxes_sorted)\n",
    "\n",
    "            proposals_decode = self.concat_axis1((proposals_decode, self.reshape(scores_sorted, self.topK_shape[idx])))\n",
    "            proposals, _, mask_valid = self.nms(proposals_decode)\n",
    "\n",
    "            mlvl_proposals = mlvl_proposals + (proposals,)\n",
    "            mlvl_mask = mlvl_mask + (mask_valid,)\n",
    "\n",
    "        proposals = self.concat_axis0(mlvl_proposals)\n",
    "        masks = self.concat_axis0(mlvl_mask)\n",
    "\n",
    "        _, _, _, _, scores = self.split(proposals)\n",
    "        scores = self.squeeze(scores)\n",
    "        topk_mask = self.cast(self.topK_mask, self.cast_type)\n",
    "        scores_using = self.select(masks, scores, topk_mask)\n",
    "\n",
    "        _, topk_inds = self.topKv2(scores_using, self.max_num)\n",
    "\n",
    "        topk_inds = self.reshape(topk_inds, self.topK_shape_stage2)\n",
    "        proposals = self.gatherND(proposals, topk_inds)\n",
    "        masks = self.gatherND(masks, topk_inds)\n",
    "        return proposals, masks\n",
    "\n",
    "\n",
    "class BboxAssignSampleForRcnn(nn.Cell):\n",
    "    \"\"\"\n",
    "    Bbox assigner and sampler definition.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Config.\n",
    "        batch_size (int): Batchsize.\n",
    "        num_bboxes (int): The anchor nums.\n",
    "        add_gt_as_proposals (bool): add gt bboxes as proposals flag.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, multiple output tensors.\n",
    "\n",
    "    Examples:\n",
    "        BboxAssignSampleForRcnn(config, 2, 1024, True)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, batch_size, num_bboxes, add_gt_as_proposals):\n",
    "        super(BboxAssignSampleForRcnn, self).__init__()\n",
    "        cfg = config\n",
    "\n",
    "        if context.get_context(\"device_target\") == \"Ascend\":\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "        else:\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.neg_iou_thr = cfg.neg_iou_thr_stage2\n",
    "        self.pos_iou_thr = cfg.pos_iou_thr_stage2\n",
    "        self.min_pos_iou = cfg.min_pos_iou_stage2\n",
    "        self.num_gts = cfg.num_gts\n",
    "        self.num_bboxes = num_bboxes\n",
    "        self.num_expected_pos = cfg.num_expected_pos_stage2\n",
    "        self.num_expected_neg = cfg.num_expected_neg_stage2\n",
    "        self.num_expected_total = cfg.num_expected_total_stage2\n",
    "\n",
    "        self.add_gt_as_proposals = add_gt_as_proposals\n",
    "        self.label_inds = Tensor(np.arange(1, self.num_gts + 1).astype(np.int32))\n",
    "        self.add_gt_as_proposals_valid = Tensor(np.array(self.add_gt_as_proposals * np.ones(self.num_gts),\n",
    "                                                         dtype=np.int32))\n",
    "\n",
    "        self.concat = P.Concat(axis=0)\n",
    "        self.max_gt = P.ArgMaxWithValue(axis=0)\n",
    "        self.max_anchor = P.ArgMaxWithValue(axis=1)\n",
    "        self.sum_inds = P.ReduceSum()\n",
    "        self.iou = P.IOU()\n",
    "        self.greaterequal = P.GreaterEqual()\n",
    "        self.greater = P.Greater()\n",
    "        self.select = P.Select()\n",
    "        self.gatherND = P.GatherNd()\n",
    "        self.squeeze = P.Squeeze()\n",
    "        self.cast = P.Cast()\n",
    "        self.logicaland = P.LogicalAnd()\n",
    "        self.less = P.Less()\n",
    "        self.random_choice_with_mask_pos = P.RandomChoiceWithMask(self.num_expected_pos)\n",
    "        self.random_choice_with_mask_neg = P.RandomChoiceWithMask(self.num_expected_neg)\n",
    "        self.reshape = P.Reshape()\n",
    "        self.equal = P.Equal()\n",
    "        self.bounding_box_encode = P.BoundingBoxEncode(means=(0.0, 0.0, 0.0, 0.0), stds=(0.1, 0.1, 0.2, 0.2))\n",
    "        self.concat_axis1 = P.Concat(axis=1)\n",
    "        self.logicalnot = P.LogicalNot()\n",
    "        self.tile = P.Tile()\n",
    "\n",
    "        # Check\n",
    "        self.check_gt_one = Tensor(np.array(-1 * np.ones((self.num_gts, 4)), dtype=self.np_cast_type))\n",
    "        self.check_anchor_two = Tensor(np.array(-2 * np.ones((self.num_bboxes, 4)), dtype=self.np_cast_type))\n",
    "\n",
    "        # Init tensor\n",
    "        self.assigned_gt_inds = Tensor(np.array(-1 * np.ones(num_bboxes), dtype=np.int32))\n",
    "        self.assigned_gt_zeros = Tensor(np.array(np.zeros(num_bboxes), dtype=np.int32))\n",
    "        self.assigned_gt_ones = Tensor(np.array(np.ones(num_bboxes), dtype=np.int32))\n",
    "        self.assigned_gt_ignores = Tensor(np.array(-1 * np.ones(num_bboxes), dtype=np.int32))\n",
    "        self.assigned_pos_ones = Tensor(np.array(np.ones(self.num_expected_pos), dtype=np.int32))\n",
    "\n",
    "        self.gt_ignores = Tensor(np.array(-1 * np.ones(self.num_gts), dtype=np.int32))\n",
    "        self.range_pos_size = Tensor(np.arange(self.num_expected_pos).astype(self.np_cast_type))\n",
    "        self.check_neg_mask = Tensor(np.array(np.ones(self.num_expected_neg - self.num_expected_pos), dtype=bool))\n",
    "        self.bboxs_neg_mask = Tensor(np.zeros((self.num_expected_neg, 4), dtype=self.np_cast_type))\n",
    "        self.labels_neg_mask = Tensor(np.array(np.zeros(self.num_expected_neg), dtype=np.uint8))\n",
    "\n",
    "        self.reshape_shape_pos = (self.num_expected_pos, 1)\n",
    "        self.reshape_shape_neg = (self.num_expected_neg, 1)\n",
    "\n",
    "        self.scalar_zero = Tensor(0.0, dtype=self.cast_type)\n",
    "        self.scalar_neg_iou_thr = Tensor(self.neg_iou_thr, dtype=self.cast_type)\n",
    "        self.scalar_pos_iou_thr = Tensor(self.pos_iou_thr, dtype=self.cast_type)\n",
    "        self.scalar_min_pos_iou = Tensor(self.min_pos_iou, dtype=self.cast_type)\n",
    "\n",
    "        self.expand_dims = P.ExpandDims()\n",
    "        self.split = P.Split(axis=1, output_num=4)\n",
    "        self.concat_last_axis = P.Concat(axis=-1)\n",
    "        self.round = P.Round()\n",
    "        self.image_h_w = Tensor([cfg.img_height, cfg.img_width, cfg.img_height, cfg.img_width], dtype=self.cast_type)\n",
    "        self.range = nn.Range(start=0, limit=cfg.num_expected_pos_stage2)\n",
    "        self.crop_and_resize = P.CropAndResize(method=\"bilinear_v2\")\n",
    "        self.mask_shape = (cfg.mask_shape[0], cfg.mask_shape[1])\n",
    "        self.squeeze_mask_last = P.Squeeze(axis=-1)\n",
    "\n",
    "    def construct(self, gt_bboxes_i, gt_labels_i, valid_mask, bboxes, gt_valids, gt_masks_i):\n",
    "        gt_bboxes_i = self.select(self.cast(self.tile(self.reshape(self.cast(gt_valids, mstype.int32), \\\n",
    "                                                                   (self.num_gts, 1)), (1, 4)), mstype.bool_), \\\n",
    "                                  gt_bboxes_i, self.check_gt_one)\n",
    "        bboxes = self.select(self.cast(self.tile(self.reshape(self.cast(valid_mask, mstype.int32), \\\n",
    "                                                              (self.num_bboxes, 1)), (1, 4)), mstype.bool_), \\\n",
    "                             bboxes, self.check_anchor_two)\n",
    "\n",
    "        overlaps = self.iou(bboxes, gt_bboxes_i)\n",
    "\n",
    "        max_overlaps_w_gt_index, max_overlaps_w_gt = self.max_gt(overlaps)\n",
    "        _, max_overlaps_w_ac = self.max_anchor(overlaps)\n",
    "\n",
    "        neg_sample_iou_mask = self.logicaland(self.greaterequal(max_overlaps_w_gt,\n",
    "                                                                self.scalar_zero),\n",
    "                                              self.less(max_overlaps_w_gt,\n",
    "                                                        self.scalar_neg_iou_thr))\n",
    "\n",
    "        assigned_gt_inds2 = self.select(neg_sample_iou_mask, self.assigned_gt_zeros, self.assigned_gt_inds)\n",
    "\n",
    "        pos_sample_iou_mask = self.greaterequal(max_overlaps_w_gt, self.scalar_pos_iou_thr)\n",
    "        assigned_gt_inds3 = self.select(pos_sample_iou_mask, \\\n",
    "                                        max_overlaps_w_gt_index + self.assigned_gt_ones, assigned_gt_inds2)\n",
    "\n",
    "        for j in range(self.num_gts):\n",
    "            max_overlaps_w_ac_j = max_overlaps_w_ac[j:j + 1:1]\n",
    "            overlaps_w_ac_j = overlaps[j:j + 1:1, ::]\n",
    "            temp1 = self.greaterequal(max_overlaps_w_ac_j, self.scalar_min_pos_iou)\n",
    "            temp2 = self.squeeze(self.equal(overlaps_w_ac_j, max_overlaps_w_ac_j))\n",
    "            pos_mask_j = self.logicaland(temp1, temp2)\n",
    "            assigned_gt_inds3 = self.select(pos_mask_j, (j + 1) * self.assigned_gt_ones, assigned_gt_inds3)\n",
    "\n",
    "        assigned_gt_inds5 = self.select(valid_mask, assigned_gt_inds3, self.assigned_gt_ignores)\n",
    "\n",
    "        bboxes = self.concat((gt_bboxes_i, bboxes))\n",
    "        label_inds_valid = self.select(gt_valids, self.label_inds, self.gt_ignores)\n",
    "        label_inds_valid = label_inds_valid * self.add_gt_as_proposals_valid\n",
    "        assigned_gt_inds5 = self.concat((label_inds_valid, assigned_gt_inds5))\n",
    "\n",
    "        # Get pos index\n",
    "        pos_index, valid_pos_index = self.random_choice_with_mask_pos(self.greater(assigned_gt_inds5, 0))\n",
    "\n",
    "        pos_check_valid = self.cast(self.greater(assigned_gt_inds5, 0), self.cast_type)\n",
    "        pos_check_valid = self.sum_inds(pos_check_valid, -1)\n",
    "        valid_pos_index = self.less(self.range_pos_size, pos_check_valid)\n",
    "        pos_index = pos_index * self.reshape(self.cast(valid_pos_index, mstype.int32), (self.num_expected_pos, 1))\n",
    "\n",
    "        num_pos = self.sum_inds(self.cast(self.logicalnot(valid_pos_index), self.cast_type), -1)\n",
    "        valid_pos_index = self.cast(valid_pos_index, mstype.int32)\n",
    "        pos_index = self.reshape(pos_index, self.reshape_shape_pos)\n",
    "        valid_pos_index = self.reshape(valid_pos_index, self.reshape_shape_pos)\n",
    "        pos_index = pos_index * valid_pos_index\n",
    "\n",
    "        pos_assigned_gt_index = self.gatherND(assigned_gt_inds5, pos_index) - self.assigned_pos_ones\n",
    "        pos_assigned_gt_index = self.reshape(pos_assigned_gt_index, self.reshape_shape_pos)\n",
    "        pos_assigned_gt_index = pos_assigned_gt_index * valid_pos_index\n",
    "\n",
    "        pos_gt_labels = self.gatherND(gt_labels_i, pos_assigned_gt_index)\n",
    "\n",
    "        # Get neg index\n",
    "        neg_index, valid_neg_index = self.random_choice_with_mask_neg(self.equal(assigned_gt_inds5, 0))\n",
    "\n",
    "        unvalid_pos_index = self.less(self.range_pos_size, num_pos)\n",
    "        valid_neg_index = self.logicaland(self.concat((self.check_neg_mask, unvalid_pos_index)), valid_neg_index)\n",
    "        neg_index = self.reshape(neg_index, self.reshape_shape_neg)\n",
    "\n",
    "        valid_neg_index = self.cast(valid_neg_index, mstype.int32)\n",
    "        valid_neg_index = self.reshape(valid_neg_index, self.reshape_shape_neg)\n",
    "        neg_index = neg_index * valid_neg_index\n",
    "\n",
    "        pos_bboxes_ = self.gatherND(bboxes, pos_index)\n",
    "\n",
    "        neg_bboxes_ = self.gatherND(bboxes, neg_index)\n",
    "        pos_assigned_gt_index = self.reshape(pos_assigned_gt_index, self.reshape_shape_pos)\n",
    "        pos_gt_bboxes_ = self.gatherND(gt_bboxes_i, pos_assigned_gt_index)\n",
    "        pos_bbox_targets_ = self.bounding_box_encode(pos_bboxes_, pos_gt_bboxes_)\n",
    "\n",
    "        # assign positive ROIs to gt masks\n",
    "        # Pick the right front and background mask for each ROI\n",
    "        roi_pos_masks_fb = self.gatherND(gt_masks_i, pos_assigned_gt_index)\n",
    "        pos_masks_fb = self.cast(roi_pos_masks_fb, mstype.float32)\n",
    "        # compute mask targets\n",
    "        x1, y1, x2, y2 = self.split(pos_bboxes_)\n",
    "        boxes = self.concat_last_axis((y1, x1, y2, x2))\n",
    "        # normalized box coordinate\n",
    "        boxes = boxes / self.image_h_w\n",
    "        box_ids = self.range()\n",
    "        pos_masks_fb = self.expand_dims(pos_masks_fb, -1)\n",
    "        boxes = self.cast(boxes, mstype.float32)\n",
    "        pos_masks_fb = self.crop_and_resize(pos_masks_fb, boxes, box_ids, self.mask_shape)\n",
    "\n",
    "        # Remove the extra dimension from masks.\n",
    "        pos_masks_fb = self.squeeze_mask_last(pos_masks_fb)\n",
    "\n",
    "        # convert gt masks targets be 0 or 1 to use with binary cross entropy loss.\n",
    "        pos_masks_fb = self.round(pos_masks_fb)\n",
    "\n",
    "        pos_masks_fb = self.cast(pos_masks_fb, self.cast_type)\n",
    "        total_bboxes = self.concat((pos_bboxes_, neg_bboxes_))\n",
    "        total_deltas = self.concat((pos_bbox_targets_, self.bboxs_neg_mask))\n",
    "        total_labels = self.concat((pos_gt_labels, self.labels_neg_mask))\n",
    "\n",
    "        valid_pos_index = self.reshape(valid_pos_index, self.reshape_shape_pos)\n",
    "        valid_neg_index = self.reshape(valid_neg_index, self.reshape_shape_neg)\n",
    "        total_mask = self.concat((valid_pos_index, valid_neg_index))\n",
    "\n",
    "        return total_bboxes, total_deltas, total_labels, total_mask, pos_bboxes_, pos_masks_fb, \\\n",
    "               pos_gt_labels, valid_pos_index\n",
    "\n",
    "\n",
    "class DenseNoTranpose(nn.Cell):\n",
    "    \"\"\"Dense method\"\"\"\n",
    "\n",
    "    def __init__(self, input_channels, output_channels, weight_init):\n",
    "        super(DenseNoTranpose, self).__init__()\n",
    "        self.weight = Parameter(initializer(weight_init, [input_channels, output_channels], mstype.float32))\n",
    "        self.bias = Parameter(initializer(\"zeros\", [output_channels], mstype.float32))\n",
    "        self.matmul = P.MatMul(transpose_b=False)\n",
    "        self.bias_add = P.BiasAdd()\n",
    "\n",
    "    def construct(self, x):\n",
    "        output = self.bias_add(self.matmul(x, self.weight), self.bias)\n",
    "        return output\n",
    "\n",
    "\n",
    "class FpnCls(nn.Cell):\n",
    "    \"\"\"dense layer of classification and box head\"\"\"\n",
    "\n",
    "    def __init__(self, input_channels, output_channels, num_classes, pool_size):\n",
    "        super(FpnCls, self).__init__()\n",
    "\n",
    "        if context.get_context(\"device_target\") == \"Ascend\":\n",
    "            self.cast_type = mstype.float32\n",
    "        else:\n",
    "            self.cast_type = mstype.float32\n",
    "\n",
    "        representation_size = input_channels * pool_size * pool_size\n",
    "        shape_0 = (output_channels, representation_size)\n",
    "        weights_0 = initializer(\"XavierUniform\", shape=shape_0[::-1], dtype=mstype.float32)\n",
    "        shape_1 = (output_channels, output_channels)\n",
    "        weights_1 = initializer(\"XavierUniform\", shape=shape_1[::-1], dtype=mstype.float32)\n",
    "        self.shared_fc_0 = DenseNoTranpose(representation_size, output_channels, weights_0).to_float(self.cast_type)\n",
    "        self.shared_fc_1 = DenseNoTranpose(output_channels, output_channels, weights_1).to_float(self.cast_type)\n",
    "\n",
    "        cls_weight = initializer('Normal', shape=[num_classes, output_channels][::-1],\n",
    "                                 dtype=mstype.float32)\n",
    "        reg_weight = initializer('Normal', shape=[num_classes * 4, output_channels][::-1],\n",
    "                                 dtype=mstype.float32)\n",
    "        self.cls_scores = DenseNoTranpose(output_channels, num_classes, cls_weight).to_float(self.cast_type)\n",
    "        self.reg_scores = DenseNoTranpose(output_channels, num_classes * 4, reg_weight).to_float(self.cast_type)\n",
    "\n",
    "        self.relu = P.ReLU()\n",
    "        self.flatten = P.Flatten()\n",
    "\n",
    "    def construct(self, x):\n",
    "        # two share fc layer\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.relu(self.shared_fc_0(x))\n",
    "        x = self.relu(self.shared_fc_1(x))\n",
    "\n",
    "        # classifier head\n",
    "        cls_scores = self.cls_scores(x)\n",
    "        # bbox head\n",
    "        reg_scores = self.reg_scores(x)\n",
    "\n",
    "        return cls_scores, reg_scores\n",
    "\n",
    "\n",
    "class RcnnCls(nn.Cell):\n",
    "    \"\"\"\n",
    "    Rcnn for classification and box regression subnet.\n",
    "\n",
    "    Args:\n",
    "        config (dict) - Config.\n",
    "        batch_size (int) - Batchsize.\n",
    "        num_classes (int) - Class number.\n",
    "        target_means (list) - Means for encode function. Default: (.0, .0, .0, .0]).\n",
    "        target_stds (list) - Stds for encode function. Default: (0.1, 0.1, 0.2, 0.2).\n",
    "\n",
    "    Returns:\n",
    "        Tuple, tuple of output tensor.\n",
    "\n",
    "    Examples:\n",
    "        RcnnCls(config=config, representation_size = 1024, batch_size=2, num_classes = 81, \\\n",
    "             target_means=(0., 0., 0., 0.), target_stds=(0.1, 0.1, 0.2, 0.2))\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 config,\n",
    "                 batch_size,\n",
    "                 num_classes,\n",
    "                 target_means=(0., 0., 0., 0.),\n",
    "                 target_stds=(0.1, 0.1, 0.2, 0.2)\n",
    "                 ):\n",
    "        super(RcnnCls, self).__init__()\n",
    "        cfg = config\n",
    "\n",
    "        if context.get_context(\"device_target\") == \"Ascend\":\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "        else:\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "\n",
    "        self.rcnn_loss_cls_weight = Tensor(np.array(cfg.rcnn_loss_cls_weight).astype(self.np_cast_type))\n",
    "        self.rcnn_loss_reg_weight = Tensor(np.array(cfg.rcnn_loss_reg_weight).astype(self.np_cast_type))\n",
    "        self.rcnn_fc_out_channels = cfg.rcnn_fc_out_channels\n",
    "        self.target_means = target_means\n",
    "        self.target_stds = target_stds\n",
    "        self.num_classes = num_classes\n",
    "        self.in_channels = cfg.rcnn_in_channels\n",
    "        self.train_batch_size = batch_size\n",
    "        self.test_batch_size = cfg.test_batch_size\n",
    "\n",
    "        self.fpn_cls = FpnCls(self.in_channels, self.rcnn_fc_out_channels, self.num_classes, cfg.roi_layer.out_size)\n",
    "        self.relu = P.ReLU()\n",
    "        self.logicaland = P.LogicalAnd()\n",
    "        self.loss_cls = P.SoftmaxCrossEntropyWithLogits()\n",
    "        self.loss_bbox = P.SmoothL1Loss(beta=1.0)\n",
    "        self.loss_mask = P.SigmoidCrossEntropyWithLogits()\n",
    "        self.reshape = P.Reshape()\n",
    "        self.onehot = P.OneHot()\n",
    "        self.greater = P.Greater()\n",
    "        self.cast = P.Cast()\n",
    "        self.sum_loss = P.ReduceSum()\n",
    "        self.tile = P.Tile()\n",
    "        self.expandims = P.ExpandDims()\n",
    "\n",
    "        self.gather = P.GatherNd()\n",
    "        self.argmax = P.ArgMaxWithValue(axis=1)\n",
    "\n",
    "        self.on_value = Tensor(1.0, mstype.float32)\n",
    "        self.off_value = Tensor(0.0, mstype.float32)\n",
    "        self.value = Tensor(1.0, self.cast_type)\n",
    "\n",
    "        self.num_bboxes = (cfg.num_expected_pos_stage2 + cfg.num_expected_neg_stage2) * batch_size\n",
    "\n",
    "        rmv_first = np.ones((self.num_bboxes, self.num_classes))\n",
    "        rmv_first[:, 0] = np.zeros((self.num_bboxes,))\n",
    "        self.rmv_first_tensor = Tensor(rmv_first.astype(self.np_cast_type))\n",
    "\n",
    "        self.num_bboxes_test = cfg.rpn_max_num * cfg.test_batch_size\n",
    "\n",
    "    def construct(self, featuremap, bbox_targets, labels, mask):\n",
    "        x_cls, x_reg = self.fpn_cls(featuremap)\n",
    "\n",
    "        if self.training:\n",
    "            bbox_weights = self.cast(self.logicaland(self.greater(labels, 0), mask), mstype.int32) * labels\n",
    "            labels = self.cast(self.onehot(labels, self.num_classes, self.on_value, self.off_value), self.cast_type)\n",
    "            bbox_targets = self.tile(self.expandims(bbox_targets, 1), (1, self.num_classes, 1))\n",
    "\n",
    "            loss_cls, loss_reg = self.loss(x_cls, x_reg,\n",
    "                                           bbox_targets, bbox_weights,\n",
    "                                           labels,\n",
    "                                           mask)\n",
    "            out = (loss_cls, loss_reg)\n",
    "        else:\n",
    "            out = (x_cls, x_reg)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def loss(self, cls_score, bbox_pred, bbox_targets, bbox_weights, labels, weights):\n",
    "        \"\"\"Loss method.\"\"\"\n",
    "        # loss_cls\n",
    "        loss_cls, _ = self.loss_cls(cls_score, labels)\n",
    "        weights = self.cast(weights, self.cast_type)\n",
    "        loss_cls = loss_cls * weights\n",
    "        loss_cls = self.sum_loss(loss_cls, (0,)) / (self.sum_loss(weights, (0,)) + 1e-5)\n",
    "\n",
    "        # loss_reg\n",
    "        bbox_weights = self.cast(self.onehot(bbox_weights, self.num_classes, self.on_value, self.off_value),\n",
    "                                 self.cast_type)\n",
    "        bbox_weights = bbox_weights * self.rmv_first_tensor  # * self.rmv_first_tensor  exclude background\n",
    "        pos_bbox_pred = self.reshape(bbox_pred, (self.num_bboxes, -1, 4))\n",
    "        loss_reg = self.loss_bbox(pos_bbox_pred, bbox_targets)\n",
    "        loss_reg = self.sum_loss(loss_reg, (2,))\n",
    "        loss_reg = loss_reg * bbox_weights\n",
    "        loss_reg = loss_reg / (self.sum_loss(weights, (0,)) + 1e-5)\n",
    "        loss_reg = self.sum_loss(loss_reg, (0, 1))\n",
    "\n",
    "        return loss_cls, loss_reg\n",
    "\n",
    "\n",
    "class FpnMask(nn.Cell):\n",
    "    \"\"\"conv layers of mask head\"\"\"\n",
    "\n",
    "    def __init__(self, input_channels, output_channels, num_classes):\n",
    "        super(FpnMask, self).__init__()\n",
    "\n",
    "        if context.get_context(\"device_target\") == \"Ascend\":\n",
    "            self.cast_type = mstype.float32\n",
    "        else:\n",
    "            self.cast_type = mstype.float32\n",
    "\n",
    "        self.mask_conv1 = nn.Conv2d(input_channels, output_channels, kernel_size=3,\n",
    "                                    pad_mode=\"same\").to_float(self.cast_type)\n",
    "        self.mask_relu1 = P.ReLU()\n",
    "\n",
    "        self.mask_conv2 = nn.Conv2d(output_channels, output_channels, kernel_size=3,\n",
    "                                    pad_mode=\"same\").to_float(self.cast_type)\n",
    "        self.mask_relu2 = P.ReLU()\n",
    "\n",
    "        self.mask_conv3 = nn.Conv2d(output_channels, output_channels, kernel_size=3,\n",
    "                                    pad_mode=\"same\").to_float(self.cast_type)\n",
    "        self.mask_relu3 = P.ReLU()\n",
    "\n",
    "        self.mask_conv4 = nn.Conv2d(output_channels, output_channels, kernel_size=3,\n",
    "                                    pad_mode=\"same\").to_float(self.cast_type)\n",
    "        self.mask_relu4 = P.ReLU()\n",
    "\n",
    "        self.mask_deconv5 = nn.Conv2dTranspose(output_channels, output_channels, kernel_size=2,\n",
    "                                               stride=2, pad_mode=\"valid\").to_float(self.cast_type)\n",
    "        self.mask_relu5 = P.ReLU()\n",
    "        self.mask_conv6 = nn.Conv2d(output_channels, num_classes, kernel_size=1, stride=1,\n",
    "                                    pad_mode=\"valid\").to_float(self.cast_type)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.mask_conv1(x)\n",
    "        x = self.mask_relu1(x)\n",
    "\n",
    "        x = self.mask_conv2(x)\n",
    "        x = self.mask_relu2(x)\n",
    "\n",
    "        x = self.mask_conv3(x)\n",
    "        x = self.mask_relu3(x)\n",
    "\n",
    "        x = self.mask_conv4(x)\n",
    "        x = self.mask_relu4(x)\n",
    "\n",
    "        x = self.mask_deconv5(x)\n",
    "        x = self.mask_relu5(x)\n",
    "\n",
    "        x = self.mask_conv6(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class RcnnMask(nn.Cell):\n",
    "    \"\"\"\n",
    "    Rcnn for mask subnet.\n",
    "\n",
    "    Args:\n",
    "        config (dict) - Config.\n",
    "        batch_size (int) - Batchsize.\n",
    "        num_classes (int) - Class number.\n",
    "        target_means (list) - Means for encode function. Default: (.0, .0, .0, .0]).\n",
    "        target_stds (list) - Stds for encode function. Default: (0.1, 0.1, 0.2, 0.2).\n",
    "\n",
    "    Returns:\n",
    "        Tuple, tuple of output tensor.\n",
    "\n",
    "    Examples:\n",
    "        RcnnMask(config=config, representation_size = 1024, batch_size=2, num_classes = 81, \\\n",
    "             target_means=(0., 0., 0., 0.), target_stds=(0.1, 0.1, 0.2, 0.2))\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 config,\n",
    "                 batch_size,\n",
    "                 num_classes,\n",
    "                 target_means=(0., 0., 0., 0.),\n",
    "                 target_stds=(0.1, 0.1, 0.2, 0.2)\n",
    "                 ):\n",
    "        super(RcnnMask, self).__init__()\n",
    "        cfg = config\n",
    "\n",
    "        if context.get_context(\"device_target\") == \"Ascend\":\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "        else:\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "\n",
    "        self.rcnn_loss_mask_fb_weight = Tensor(np.array(cfg.rcnn_loss_mask_fb_weight).astype(self.np_cast_type))\n",
    "        self.rcnn_mask_out_channels = cfg.rcnn_mask_out_channels\n",
    "        self.target_means = target_means\n",
    "        self.target_stds = target_stds\n",
    "        self.num_classes = num_classes\n",
    "        self.in_channels = cfg.rcnn_in_channels\n",
    "\n",
    "        self.fpn_mask = FpnMask(self.in_channels, self.rcnn_mask_out_channels, self.num_classes)\n",
    "\n",
    "        self.logicaland = P.LogicalAnd()\n",
    "        self.loss_mask = P.SigmoidCrossEntropyWithLogits()\n",
    "        self.onehot = P.OneHot()\n",
    "        self.greater = P.Greater()\n",
    "        self.cast = P.Cast()\n",
    "        self.sum_loss = P.ReduceSum()\n",
    "        self.tile = P.Tile()\n",
    "        self.expandims = P.ExpandDims()\n",
    "\n",
    "        self.on_value = Tensor(1.0, mstype.float32)\n",
    "        self.off_value = Tensor(0.0, mstype.float32)\n",
    "\n",
    "        self.num_bboxes = cfg.num_expected_pos_stage2 * batch_size\n",
    "        rmv_first = np.ones((self.num_bboxes, self.num_classes))\n",
    "        rmv_first[:, 0] = np.zeros((self.num_bboxes,))\n",
    "        self.rmv_first_tensor = Tensor(rmv_first.astype(self.np_cast_type))\n",
    "        self.mean_loss = P.ReduceMean()\n",
    "\n",
    "    def construct(self, mask_featuremap, labels=None, mask=None, mask_fb_targets=None):\n",
    "        x_mask_fb = self.fpn_mask(mask_featuremap)\n",
    "\n",
    "        if self.training:\n",
    "            bbox_weights = self.cast(self.logicaland(self.greater(labels, 0), mask), mstype.int32) * labels\n",
    "            mask_fb_targets = self.tile(self.expandims(mask_fb_targets, 1), (1, self.num_classes, 1, 1))\n",
    "\n",
    "            loss_mask_fb = self.loss(x_mask_fb, bbox_weights, mask, mask_fb_targets)\n",
    "            out = loss_mask_fb\n",
    "        else:\n",
    "            out = x_mask_fb\n",
    "\n",
    "        return out\n",
    "\n",
    "    def loss(self, masks_fb_pred, bbox_weights, weights, masks_fb_targets):\n",
    "        \"\"\"Loss method.\"\"\"\n",
    "        weights = self.cast(weights, self.cast_type)\n",
    "        bbox_weights = self.cast(self.onehot(bbox_weights, self.num_classes, self.on_value, self.off_value),\n",
    "                                 self.cast_type)\n",
    "        bbox_weights = bbox_weights * self.rmv_first_tensor  # * self.rmv_first_tensor  exclude background\n",
    "\n",
    "        # loss_mask_fb\n",
    "        masks_fb_targets = self.cast(masks_fb_targets, self.cast_type)\n",
    "        loss_mask_fb = self.loss_mask(masks_fb_pred, masks_fb_targets)\n",
    "        loss_mask_fb = self.mean_loss(loss_mask_fb, (2, 3))\n",
    "        loss_mask_fb = loss_mask_fb * bbox_weights\n",
    "        loss_mask_fb = loss_mask_fb / (self.sum_loss(weights, (0,)) + 1e-5)\n",
    "        loss_mask_fb = self.sum_loss(loss_mask_fb, (0, 1))\n",
    "\n",
    "        return loss_mask_fb\n",
    "\n",
    "\n",
    "class AnchorGenerator():\n",
    "    \"\"\"Anchor generator for MasKRcnn.\"\"\"\n",
    "    def __init__(self, base_size, scales, ratios, scale_major=True, ctr=None):\n",
    "        \"\"\"Anchor generator init method.\"\"\"\n",
    "        self.base_size = base_size\n",
    "        self.scales = np.array(scales)\n",
    "        self.ratios = np.array(ratios)\n",
    "        self.scale_major = scale_major\n",
    "        self.ctr = ctr\n",
    "        self.base_anchors = self.gen_base_anchors()\n",
    "\n",
    "    def gen_base_anchors(self):\n",
    "        \"\"\"Generate a single anchor.\"\"\"\n",
    "        w = self.base_size\n",
    "        h = self.base_size\n",
    "        if self.ctr is None:\n",
    "            x_ctr = 0.5 * (w - 1)\n",
    "            y_ctr = 0.5 * (h - 1)\n",
    "        else:\n",
    "            x_ctr, y_ctr = self.ctr\n",
    "\n",
    "        h_ratios = np.sqrt(self.ratios)\n",
    "        w_ratios = 1 / h_ratios\n",
    "        if self.scale_major:\n",
    "            ws = (w * w_ratios[:, None] * self.scales[None, :]).reshape(-1)\n",
    "            hs = (h * h_ratios[:, None] * self.scales[None, :]).reshape(-1)\n",
    "        else:\n",
    "            ws = (w * self.scales[:, None] * w_ratios[None, :]).reshape(-1)\n",
    "            hs = (h * self.scales[:, None] * h_ratios[None, :]).reshape(-1)\n",
    "\n",
    "        base_anchors = np.stack(\n",
    "            [\n",
    "                x_ctr - 0.5 * (ws - 1), y_ctr - 0.5 * (hs - 1),\n",
    "                x_ctr + 0.5 * (ws - 1), y_ctr + 0.5 * (hs - 1)\n",
    "            ],\n",
    "            axis=-1).round()\n",
    "\n",
    "        return base_anchors\n",
    "\n",
    "    def _meshgrid(self, x, y, row_major=True):\n",
    "        \"\"\"Generate grid.\"\"\"\n",
    "        xx = np.repeat(x.reshape(1, len(x)), len(y), axis=0).reshape(-1)\n",
    "        yy = np.repeat(y, len(x))\n",
    "        if row_major:\n",
    "            return xx, yy\n",
    "\n",
    "        return yy, xx\n",
    "\n",
    "    def grid_anchors(self, featmap_size, stride=16):\n",
    "        \"\"\"Generate anchor list.\"\"\"\n",
    "        base_anchors = self.base_anchors\n",
    "\n",
    "        feat_h, feat_w = featmap_size\n",
    "        shift_x = np.arange(0, feat_w) * stride\n",
    "        shift_y = np.arange(0, feat_h) * stride\n",
    "        shift_xx, shift_yy = self._meshgrid(shift_x, shift_y)\n",
    "        shifts = np.stack([shift_xx, shift_yy, shift_xx, shift_yy], axis=-1)\n",
    "        shifts = shifts.astype(base_anchors.dtype)\n",
    "        # first feat_w elements correspond to the first row of shifts\n",
    "        # add A anchors (1, A, 4) to K shifts (K, 1, 4) to get\n",
    "        # shifted anchors (K, A, 4), reshape to (K*A, 4)\n",
    "\n",
    "        all_anchors = base_anchors[None, :, :] + shifts[:, None, :]\n",
    "        all_anchors = all_anchors.reshape(-1, 4)\n",
    "\n",
    "        return all_anchors\n",
    "\n",
    "\n",
    "class ROIAlign(nn.Cell):\n",
    "    \"\"\"\n",
    "    Extract RoI features from mulitiple feature map.\n",
    "\n",
    "    Args:\n",
    "        out_size_h (int) - RoI height.\n",
    "        out_size_w (int) - RoI width.\n",
    "        spatial_scale (int) - RoI spatial scale.\n",
    "        sample_num (int) - RoI sample number.\n",
    "        roi_align_mode (int)- RoI align mode\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 out_size_h,\n",
    "                 out_size_w,\n",
    "                 spatial_scale,\n",
    "                 sample_num=0,\n",
    "                 roi_align_mode=1):\n",
    "        super(ROIAlign, self).__init__()\n",
    "\n",
    "        self.out_size = (out_size_h, out_size_w)\n",
    "        self.spatial_scale = float(spatial_scale)\n",
    "        self.sample_num = int(sample_num)\n",
    "        self.align_op = P.ROIAlign(self.out_size[0], self.out_size[1],\n",
    "                                   self.spatial_scale, self.sample_num, roi_align_mode)\n",
    "\n",
    "    def construct(self, features, rois):\n",
    "        return self.align_op(features, rois)\n",
    "\n",
    "    def __repr__(self):\n",
    "        format_str = self.__class__.__name__\n",
    "        format_str += '(out_size={}, spatial_scale={}, sample_num={}'.format(\n",
    "            self.out_size, self.spatial_scale, self.sample_num)\n",
    "        return format_str\n",
    "\n",
    "\n",
    "class SingleRoIExtractor(nn.Cell):\n",
    "    \"\"\"\n",
    "    Extract RoI features from a single level feature map.\n",
    "\n",
    "    If there are multiple input feature levels, each RoI is mapped to a level\n",
    "    according to its scale.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Config\n",
    "        roi_layer (dict): Specify RoI layer type and arguments.\n",
    "        out_channels (int): Output channels of RoI layers.\n",
    "        featmap_strides (int): Strides of input feature maps.\n",
    "        batch_size (int)： Batchsize.\n",
    "        finest_scale (int): Scale threshold of mapping to level 0.\n",
    "        mask (bool): Specify ROIAlign for cls or mask branch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 config,\n",
    "                 roi_layer,\n",
    "                 out_channels,\n",
    "                 featmap_strides,\n",
    "                 batch_size=1,\n",
    "                 finest_scale=56,\n",
    "                 mask=False):\n",
    "        super(SingleRoIExtractor, self).__init__()\n",
    "        cfg = config\n",
    "        self.train_batch_size = batch_size\n",
    "        self.out_channels = out_channels\n",
    "        self.featmap_strides = featmap_strides\n",
    "        self.num_levels = len(self.featmap_strides)\n",
    "        self.out_size = config.roi_layer.mask_out_size if mask else config.roi_layer.out_size\n",
    "        self.mask = mask\n",
    "        self.sample_num = config.roi_layer.sample_num\n",
    "        self.roi_layers = self.build_roi_layers(self.featmap_strides)\n",
    "        self.roi_layers = L.CellList(self.roi_layers)\n",
    "\n",
    "        self.sqrt = P.Sqrt()\n",
    "        self.log = P.Log()\n",
    "        self.finest_scale_ = finest_scale\n",
    "        self.clamp = C.clip_by_value\n",
    "\n",
    "        self.cast = P.Cast()\n",
    "        self.equal = P.Equal()\n",
    "        self.select = P.Select()\n",
    "\n",
    "        _mode_16 = False\n",
    "        self.dtype = np.float16 if _mode_16 else np.float32\n",
    "        self.ms_dtype = mstype.float16 if _mode_16 else mstype.float32\n",
    "        self.set_train_local(cfg, training=True)\n",
    "\n",
    "    def set_train_local(self, config, training=True):\n",
    "        \"\"\"Set training flag.\"\"\"\n",
    "        self.training_local = training\n",
    "\n",
    "        cfg = config\n",
    "        # Init tensor\n",
    "        roi_sample_num = cfg.num_expected_pos_stage2 if self.mask else cfg.roi_sample_num\n",
    "        self.batch_size = roi_sample_num if self.training_local else cfg.rpn_max_num\n",
    "        self.batch_size = self.train_batch_size*self.batch_size \\\n",
    "            if self.training_local else cfg.test_batch_size*self.batch_size\n",
    "        self.ones = Tensor(np.array(np.ones((self.batch_size, 1)), dtype=self.dtype))\n",
    "        finest_scale = np.array(np.ones((self.batch_size, 1)), dtype=self.dtype) * self.finest_scale_\n",
    "        self.finest_scale = Tensor(finest_scale)\n",
    "        self.epslion = Tensor(np.array(np.ones((self.batch_size, 1)), dtype=self.dtype)*self.dtype(1e-6))\n",
    "        self.zeros = Tensor(np.array(np.zeros((self.batch_size, 1)), dtype=np.int32))\n",
    "        self.max_levels = Tensor(np.array(np.ones((self.batch_size, 1)), dtype=np.int32)*(self.num_levels-1))\n",
    "        self.twos = Tensor(np.array(np.ones((self.batch_size, 1)), dtype=self.dtype) * 2)\n",
    "        self.res_ = Tensor(np.array(np.zeros((self.batch_size, self.out_channels,\n",
    "                                              self.out_size, self.out_size)), dtype=self.dtype))\n",
    "    def num_inputs(self):\n",
    "        return len(self.featmap_strides)\n",
    "\n",
    "    def init_weights(self):\n",
    "        pass\n",
    "\n",
    "    def log2(self, value):\n",
    "        return self.log(value) / self.log(self.twos)\n",
    "\n",
    "    def build_roi_layers(self, featmap_strides):\n",
    "        roi_layers = []\n",
    "        for s in featmap_strides:\n",
    "            layer_cls = ROIAlign(self.out_size, self.out_size,\n",
    "                                 spatial_scale=1 / s,\n",
    "                                 sample_num=self.sample_num,\n",
    "                                 roi_align_mode=0)\n",
    "            roi_layers.append(layer_cls)\n",
    "        return roi_layers\n",
    "\n",
    "    def _c_map_roi_levels(self, rois):\n",
    "        \"\"\"Map rois to corresponding feature levels by scales.\n",
    "\n",
    "        - scale < finest_scale * 2: level 0\n",
    "        - finest_scale * 2 <= scale < finest_scale * 4: level 1\n",
    "        - finest_scale * 4 <= scale < finest_scale * 8: level 2\n",
    "        - scale >= finest_scale * 8: level 3\n",
    "\n",
    "        Args:\n",
    "            rois (Tensor): Input RoIs, shape (k, 5).\n",
    "            num_levels (int): Total level number.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Level index (0-based) of each RoI, shape (k, )\n",
    "        \"\"\"\n",
    "        scale = self.sqrt(rois[::, 3:4:1] - rois[::, 1:2:1] + self.ones) * \\\n",
    "             self.sqrt(rois[::, 4:5:1] - rois[::, 2:3:1] + self.ones)\n",
    "\n",
    "        target_lvls = self.log2(scale / self.finest_scale + self.epslion)\n",
    "        target_lvls = P.Floor()(target_lvls)\n",
    "        target_lvls = self.cast(target_lvls, mstype.int32)\n",
    "        target_lvls = self.clamp(target_lvls, self.zeros, self.max_levels)\n",
    "\n",
    "        return target_lvls\n",
    "\n",
    "    def construct(self, rois, feat1, feat2, feat3, feat4):\n",
    "        feats = (feat1, feat2, feat3, feat4)\n",
    "        res = self.res_\n",
    "        target_lvls = self._c_map_roi_levels(rois)\n",
    "        for i in range(self.num_levels):\n",
    "            mask = self.equal(target_lvls, P.ScalarToArray()(i))\n",
    "            mask = P.Reshape()(mask, (-1, 1, 1, 1))\n",
    "            roi_feats_t = self.roi_layers[i](feats[i], rois)\n",
    "            mask = self.cast(P.Tile()(self.cast(mask, mstype.int32), (1, 256, self.out_size, self.out_size)),\n",
    "                             mstype.bool_)\n",
    "            res = self.select(mask, roi_feats_t, res)\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "class MaskRCNN(nn.Cell):\n",
    "    \"\"\"\n",
    "    MaskRcnn Network.\n",
    "\n",
    "    Note:\n",
    "        backbone = resnet50\n",
    "\n",
    "    Returns:\n",
    "        Tuple, tuple of output tensor.\n",
    "        rpn_loss: Scalar, Total loss of RPN subnet.\n",
    "        rcnn_loss: Scalar, Total loss of RCNN subnet.\n",
    "        rpn_cls_loss: Scalar, Classification loss of RPN subnet.\n",
    "        rpn_reg_loss: Scalar, Regression loss of RPN subnet.\n",
    "        rcnn_cls_loss: Scalar, Classification loss of RCNNcls subnet.\n",
    "        rcnn_reg_loss: Scalar, Regression loss of RCNNcls subnet.\n",
    "        rcnn_mask_loss: Scalar, mask loss of RCNNmask subnet.\n",
    "\n",
    "    Examples:\n",
    "        net = Mask_Rcnn_Resnet50()\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(MaskRCNN, self).__init__()\n",
    "\n",
    "        if context.get_context(\"device_target\") == \"Ascend\":\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "        else:\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "\n",
    "        self.train_batch_size = config.batch_size\n",
    "        self.num_classes = config.num_classes\n",
    "        self.anchor_scales = config.anchor_scales\n",
    "        self.anchor_ratios = config.anchor_ratios\n",
    "        self.anchor_strides = config.anchor_strides\n",
    "        self.target_means = tuple(config.rcnn_target_means)\n",
    "        self.target_stds = tuple(config.rcnn_target_stds)\n",
    "\n",
    "        # Anchor generator\n",
    "        anchor_base_sizes = None\n",
    "        self.anchor_base_sizes = list(\n",
    "            self.anchor_strides) if anchor_base_sizes is None else anchor_base_sizes\n",
    "\n",
    "        self.anchor_generators = []\n",
    "        for anchor_base in self.anchor_base_sizes:\n",
    "            self.anchor_generators.append(\n",
    "                AnchorGenerator(anchor_base, self.anchor_scales, self.anchor_ratios))\n",
    "\n",
    "        self.num_anchors = len(self.anchor_ratios) * len(self.anchor_scales)\n",
    "\n",
    "        featmap_sizes = config.feature_shapes\n",
    "        assert len(featmap_sizes) == len(self.anchor_generators)\n",
    "\n",
    "        self.anchor_list = self.get_anchors(featmap_sizes)\n",
    "\n",
    "        # Backbone resnet50\n",
    "        self.backbone = ResNet(ResidualBlock,\n",
    "                                  config.resnet_block,\n",
    "                                  config.resnet_in_channels,\n",
    "                                  config.resnet_out_channels,\n",
    "                                  False)\n",
    "\n",
    "        # Fpn\n",
    "        self.fpn_ncek = FeatPyramidNeck(config.fpn_in_channels,\n",
    "                                        config.fpn_out_channels,\n",
    "                                        config.fpn_num_outs,\n",
    "                                        config.feature_shapes)\n",
    "\n",
    "        # Rpn and rpn loss\n",
    "        self.gt_labels_stage1 = Tensor(np.ones((self.train_batch_size, config.num_gts)).astype(np.uint8))\n",
    "        self.rpn_with_loss = RPN(config,\n",
    "                                 self.train_batch_size,\n",
    "                                 config.rpn_in_channels,\n",
    "                                 config.rpn_feat_channels,\n",
    "                                 config.num_anchors,\n",
    "                                 config.rpn_cls_out_channels)\n",
    "\n",
    "        # Proposal\n",
    "        self.proposal_generator = Proposal(config,\n",
    "                                           self.train_batch_size,\n",
    "                                           config.activate_num_classes,\n",
    "                                           config.use_sigmoid_cls)\n",
    "        self.proposal_generator.set_train_local(config, True)\n",
    "        self.proposal_generator_test = Proposal(config,\n",
    "                                                config.test_batch_size,\n",
    "                                                config.activate_num_classes,\n",
    "                                                config.use_sigmoid_cls)\n",
    "        self.proposal_generator_test.set_train_local(config, False)\n",
    "\n",
    "        # Assign and sampler stage two\n",
    "        self.bbox_assigner_sampler_for_rcnn = BboxAssignSampleForRcnn(config, self.train_batch_size,\n",
    "                                                                      config.num_bboxes_stage2, True)\n",
    "        self.decode = P.BoundingBoxDecode(max_shape=(768, 1280), means=self.target_means, \\\n",
    "                                          stds=self.target_stds)\n",
    "\n",
    "        # Roi\n",
    "        self.init_roi(config)\n",
    "\n",
    "        # Rcnn\n",
    "        self.rcnn_cls = RcnnCls(config, self.train_batch_size, self.num_classes)\n",
    "        self.rcnn_mask = RcnnMask(config, self.train_batch_size, self.num_classes)\n",
    "\n",
    "        # Op declare\n",
    "        self.squeeze = P.Squeeze()\n",
    "        self.cast = P.Cast()\n",
    "\n",
    "        self.concat = P.Concat(axis=0)\n",
    "        self.concat_1 = P.Concat(axis=1)\n",
    "        self.concat_2 = P.Concat(axis=2)\n",
    "        self.reshape = P.Reshape()\n",
    "        self.select = P.Select()\n",
    "        self.greater = P.Greater()\n",
    "        self.transpose = P.Transpose()\n",
    "\n",
    "        # Test mode\n",
    "        self.init_test_mode(config)\n",
    "\n",
    "        # Improve speed\n",
    "        self.concat_start = min(self.num_classes - 2, 55)\n",
    "        self.concat_end = (self.num_classes - 1)\n",
    "\n",
    "        # Init tensor\n",
    "        self.init_tensor(config)\n",
    "\n",
    "    def init_roi(self, config):\n",
    "        self.roi_align = SingleRoIExtractor(config,\n",
    "                                            config.roi_layer,\n",
    "                                            config.roi_align_out_channels,\n",
    "                                            config.roi_align_featmap_strides,\n",
    "                                            self.train_batch_size,\n",
    "                                            config.roi_align_finest_scale,\n",
    "                                            mask=False)\n",
    "        self.roi_align.set_train_local(config, True)\n",
    "\n",
    "        self.roi_align_mask = SingleRoIExtractor(config,\n",
    "                                                 config.roi_layer,\n",
    "                                                 config.roi_align_out_channels,\n",
    "                                                 config.roi_align_featmap_strides,\n",
    "                                                 self.train_batch_size,\n",
    "                                                 config.roi_align_finest_scale,\n",
    "                                                 mask=True)\n",
    "        self.roi_align_mask.set_train_local(config, True)\n",
    "\n",
    "        self.roi_align_test = SingleRoIExtractor(config,\n",
    "                                                 config.roi_layer,\n",
    "                                                 config.roi_align_out_channels,\n",
    "                                                 config.roi_align_featmap_strides,\n",
    "                                                 1,\n",
    "                                                 config.roi_align_finest_scale,\n",
    "                                                 mask=False)\n",
    "        self.roi_align_test.set_train_local(config, False)\n",
    "\n",
    "        self.roi_align_mask_test = SingleRoIExtractor(config,\n",
    "                                                      config.roi_layer,\n",
    "                                                      config.roi_align_out_channels,\n",
    "                                                      config.roi_align_featmap_strides,\n",
    "                                                      1,\n",
    "                                                      config.roi_align_finest_scale,\n",
    "                                                      mask=True)\n",
    "        self.roi_align_mask_test.set_train_local(config, False)\n",
    "\n",
    "    def init_test_mode(self, config):\n",
    "        self.test_batch_size = config.test_batch_size\n",
    "        self.split = P.Split(axis=0, output_num=self.test_batch_size)\n",
    "        self.split_shape = P.Split(axis=0, output_num=4)\n",
    "        self.split_scores = P.Split(axis=1, output_num=self.num_classes)\n",
    "        self.split_fb_mask = P.Split(axis=1, output_num=self.num_classes)\n",
    "        self.split_cls = P.Split(axis=0, output_num=self.num_classes-1)\n",
    "        self.tile = P.Tile()\n",
    "        self.gather = P.GatherNd()\n",
    "\n",
    "        self.rpn_max_num = config.rpn_max_num\n",
    "\n",
    "        self.zeros_for_nms = Tensor(np.zeros((self.rpn_max_num, 3)).astype(self.np_cast_type))\n",
    "        self.ones_mask = np.ones((self.rpn_max_num, 1)).astype(bool)\n",
    "        self.zeros_mask = np.zeros((self.rpn_max_num, 1)).astype(bool)\n",
    "        self.bbox_mask = Tensor(np.concatenate((self.ones_mask, self.zeros_mask,\n",
    "                                                self.ones_mask, self.zeros_mask), axis=1))\n",
    "        self.nms_pad_mask = Tensor(np.concatenate((self.ones_mask, self.ones_mask,\n",
    "                                                   self.ones_mask, self.ones_mask, self.zeros_mask), axis=1))\n",
    "\n",
    "        self.test_score_thresh = Tensor(np.ones((self.rpn_max_num, 1)).astype(self.np_cast_type) * \\\n",
    "                                        config.test_score_thr)\n",
    "        self.test_score_zeros = Tensor(np.ones((self.rpn_max_num, 1)).astype(self.np_cast_type) * 0)\n",
    "        self.test_box_zeros = Tensor(np.ones((self.rpn_max_num, 4)).astype(self.np_cast_type) * -1)\n",
    "        self.test_iou_thr = Tensor(np.ones((self.rpn_max_num, 1)).astype(self.np_cast_type) * config.test_iou_thr)\n",
    "        self.test_max_per_img = config.test_max_per_img\n",
    "        self.nms_test = P.NMSWithMask(config.test_iou_thr)\n",
    "        self.softmax = P.Softmax(axis=1)\n",
    "        self.logicand = P.LogicalAnd()\n",
    "        self.oneslike = P.OnesLike()\n",
    "        self.test_topk = P.TopK(sorted=True)\n",
    "        self.test_num_proposal = self.test_batch_size * self.rpn_max_num\n",
    "\n",
    "    def init_tensor(self, config):\n",
    "        roi_align_index = [np.array(np.ones((config.num_expected_pos_stage2 + \\\n",
    "                                             config.num_expected_neg_stage2, 1)) * i,\n",
    "                                    dtype=self.np_cast_type) for i in range(self.train_batch_size)]\n",
    "\n",
    "        roi_align_index_test = [np.array(np.ones((config.rpn_max_num, 1)) * i, dtype=self.np_cast_type) \\\n",
    "                                for i in range(self.test_batch_size)]\n",
    "\n",
    "        self.roi_align_index_tensor = Tensor(np.concatenate(roi_align_index))\n",
    "        self.roi_align_index_test_tensor = Tensor(np.concatenate(roi_align_index_test))\n",
    "\n",
    "        roi_align_index_pos = [np.array(np.ones((config.num_expected_pos_stage2, 1)) * i,\n",
    "                                        dtype=self.np_cast_type) for i in range(self.train_batch_size)]\n",
    "        self.roi_align_index_tensor_pos = Tensor(np.concatenate(roi_align_index_pos))\n",
    "\n",
    "        self.rcnn_loss_cls_weight = Tensor(np.array(config.rcnn_loss_cls_weight).astype(self.np_cast_type))\n",
    "        self.rcnn_loss_reg_weight = Tensor(np.array(config.rcnn_loss_reg_weight).astype(self.np_cast_type))\n",
    "        self.rcnn_loss_mask_fb_weight = Tensor(np.array(config.rcnn_loss_mask_fb_weight).astype(self.np_cast_type))\n",
    "\n",
    "        self.argmax_with_value = P.ArgMaxWithValue(axis=1)\n",
    "        self.on_value = Tensor(1.0, mstype.float32)\n",
    "        self.off_value = Tensor(0.0, mstype.float32)\n",
    "        self.onehot = P.OneHot()\n",
    "        self.reducesum = P.ReduceSum()\n",
    "        self.sigmoid = P.Sigmoid()\n",
    "        self.expand_dims = P.ExpandDims()\n",
    "        self.test_mask_fb_zeros = Tensor(np.zeros((self.rpn_max_num, 28, 28)).astype(self.np_cast_type))\n",
    "        self.value = Tensor(1.0, self.cast_type)\n",
    "\n",
    "    def construct(self, img_data, img_metas, gt_bboxes, gt_labels, gt_valids, gt_masks):\n",
    "        \"\"\"Construct for Mask R-CNN net.\"\"\"\n",
    "        x = self.backbone(img_data)\n",
    "        x = self.fpn_ncek(x)\n",
    "\n",
    "        rpn_loss, cls_score, bbox_pred, rpn_cls_loss, rpn_reg_loss, _ = self.rpn_with_loss(x,\n",
    "                                                                                           img_metas,\n",
    "                                                                                           self.anchor_list,\n",
    "                                                                                           gt_bboxes,\n",
    "                                                                                           self.gt_labels_stage1,\n",
    "                                                                                           gt_valids)\n",
    "\n",
    "        if self.training:\n",
    "            proposal, proposal_mask = self.proposal_generator(cls_score, bbox_pred, self.anchor_list)\n",
    "        else:\n",
    "            proposal, proposal_mask = self.proposal_generator_test(cls_score, bbox_pred, self.anchor_list)\n",
    "\n",
    "        gt_labels = self.cast(gt_labels, mstype.int32)\n",
    "        gt_valids = self.cast(gt_valids, mstype.int32)\n",
    "        bboxes_tuple = ()\n",
    "        deltas_tuple = ()\n",
    "        labels_tuple = ()\n",
    "        mask_tuple = ()\n",
    "\n",
    "        pos_bboxes_tuple = ()\n",
    "        pos_mask_fb_tuple = ()\n",
    "        pos_labels_tuple = ()\n",
    "        pos_mask_tuple = ()\n",
    "\n",
    "        if self.training:\n",
    "            for i in range(self.train_batch_size):\n",
    "                gt_bboxes_i = self.squeeze(gt_bboxes[i:i + 1:1, ::])\n",
    "\n",
    "                gt_labels_i = self.squeeze(gt_labels[i:i + 1:1, ::])\n",
    "                gt_labels_i = self.cast(gt_labels_i, mstype.uint8)\n",
    "\n",
    "                gt_valids_i = self.squeeze(gt_valids[i:i + 1:1, ::])\n",
    "                gt_valids_i = self.cast(gt_valids_i, mstype.bool_)\n",
    "\n",
    "                gt_masks_i = self.squeeze(gt_masks[i:i + 1:1, ::])\n",
    "                gt_masks_i = self.cast(gt_masks_i, mstype.bool_)\n",
    "\n",
    "                bboxes, deltas, labels, mask, pos_bboxes, pos_mask_fb, pos_labels, pos_mask = \\\n",
    "                    self.bbox_assigner_sampler_for_rcnn(gt_bboxes_i,\n",
    "                                                        gt_labels_i,\n",
    "                                                        proposal_mask[i],\n",
    "                                                        proposal[i][::, 0:4:1],\n",
    "                                                        gt_valids_i,\n",
    "                                                        gt_masks_i)\n",
    "                bboxes_tuple += (bboxes,)\n",
    "                deltas_tuple += (deltas,)\n",
    "                labels_tuple += (labels,)\n",
    "                mask_tuple += (mask,)\n",
    "\n",
    "                pos_bboxes_tuple += (pos_bboxes,)\n",
    "                pos_mask_fb_tuple += (pos_mask_fb,)\n",
    "                pos_labels_tuple += (pos_labels,)\n",
    "                pos_mask_tuple += (pos_mask,)\n",
    "\n",
    "            bbox_targets = self.concat(deltas_tuple)\n",
    "            rcnn_labels = self.concat(labels_tuple)\n",
    "            bbox_targets = F.stop_gradient(bbox_targets)\n",
    "            rcnn_labels = F.stop_gradient(rcnn_labels)\n",
    "            rcnn_labels = self.cast(rcnn_labels, mstype.int32)\n",
    "\n",
    "            rcnn_pos_masks_fb = self.concat(pos_mask_fb_tuple)\n",
    "            rcnn_pos_masks_fb = F.stop_gradient(rcnn_pos_masks_fb)\n",
    "            rcnn_pos_labels = self.concat(pos_labels_tuple)\n",
    "            rcnn_pos_labels = F.stop_gradient(rcnn_pos_labels)\n",
    "            rcnn_pos_labels = self.cast(rcnn_pos_labels, mstype.int32)\n",
    "        else:\n",
    "            mask_tuple += proposal_mask\n",
    "            bbox_targets = proposal_mask\n",
    "            rcnn_labels = proposal_mask\n",
    "\n",
    "            rcnn_pos_masks_fb = proposal_mask\n",
    "            rcnn_pos_labels = proposal_mask\n",
    "            for p_i in proposal:\n",
    "                bboxes_tuple += (p_i[::, 0:4:1],)\n",
    "\n",
    "        bboxes_all, rois, pos_rois = self.rois(bboxes_tuple, pos_bboxes_tuple)\n",
    "\n",
    "        if self.training:\n",
    "            roi_feats = self.roi_align(rois,\n",
    "                                       self.cast(x[0], mstype.float32),\n",
    "                                       self.cast(x[1], mstype.float32),\n",
    "                                       self.cast(x[2], mstype.float32),\n",
    "                                       self.cast(x[3], mstype.float32))\n",
    "        else:\n",
    "            roi_feats = self.roi_align_test(rois,\n",
    "                                            self.cast(x[0], mstype.float32),\n",
    "                                            self.cast(x[1], mstype.float32),\n",
    "                                            self.cast(x[2], mstype.float32),\n",
    "                                            self.cast(x[3], mstype.float32))\n",
    "\n",
    "\n",
    "        roi_feats = self.cast(roi_feats, self.cast_type)\n",
    "        rcnn_masks = self.concat(mask_tuple)\n",
    "        rcnn_masks = F.stop_gradient(rcnn_masks)\n",
    "        rcnn_mask_squeeze = self.squeeze(self.cast(rcnn_masks, mstype.bool_))\n",
    "\n",
    "        rcnn_pos_masks = self.concat(pos_mask_tuple)\n",
    "        rcnn_pos_masks = F.stop_gradient(rcnn_pos_masks)\n",
    "        rcnn_pos_mask_squeeze = self.squeeze(self.cast(rcnn_pos_masks, mstype.bool_))\n",
    "\n",
    "        rcnn_cls_loss, rcnn_reg_loss = self.rcnn_cls(roi_feats,\n",
    "                                                     bbox_targets,\n",
    "                                                     rcnn_labels,\n",
    "                                                     rcnn_mask_squeeze)\n",
    "\n",
    "        if self.training:\n",
    "            return self.get_output_train(pos_rois, x, rcnn_pos_labels, rcnn_pos_mask_squeeze, rcnn_pos_masks_fb,\n",
    "                                         rpn_loss, rpn_cls_loss, rpn_reg_loss, rcnn_cls_loss, rcnn_reg_loss)\n",
    "\n",
    "        return self.get_output_eval(x, bboxes_all, rcnn_cls_loss, rcnn_reg_loss, rcnn_masks, img_metas)\n",
    "\n",
    "    def rois(self, bboxes_tuple, pos_bboxes_tuple):\n",
    "        pos_rois = None\n",
    "        if self.training:\n",
    "            if self.train_batch_size > 1:\n",
    "                bboxes_all = self.concat(bboxes_tuple)\n",
    "                pos_bboxes_all = self.concat(pos_bboxes_tuple)\n",
    "            else:\n",
    "                bboxes_all = bboxes_tuple[0]\n",
    "                pos_bboxes_all = pos_bboxes_tuple[0]\n",
    "            rois = self.concat_1((self.roi_align_index_tensor, bboxes_all))\n",
    "            pos_rois = self.concat_1((self.roi_align_index_tensor_pos, pos_bboxes_all))\n",
    "            pos_rois = self.cast(pos_rois, mstype.float32)\n",
    "            pos_rois = F.stop_gradient(pos_rois)\n",
    "        else:\n",
    "            if self.test_batch_size > 1:\n",
    "                bboxes_all = self.concat(bboxes_tuple)\n",
    "            else:\n",
    "                bboxes_all = bboxes_tuple[0]\n",
    "            rois = self.concat_1((self.roi_align_index_test_tensor, bboxes_all))\n",
    "\n",
    "        rois = self.cast(rois, mstype.float32)\n",
    "        rois = F.stop_gradient(rois)\n",
    "\n",
    "        return bboxes_all, rois, pos_rois\n",
    "\n",
    "    def get_output_train(self, pos_rois, x, rcnn_pos_labels, rcnn_pos_mask_squeeze, rcnn_pos_masks_fb,\n",
    "                         rpn_loss, rpn_cls_loss, rpn_reg_loss, rcnn_cls_loss, rcnn_reg_loss):\n",
    "        output = ()\n",
    "        roi_feats_mask = self.roi_align_mask(pos_rois,\n",
    "                                             self.cast(x[0], mstype.float32),\n",
    "                                             self.cast(x[1], mstype.float32),\n",
    "                                             self.cast(x[2], mstype.float32),\n",
    "                                             self.cast(x[3], mstype.float32))\n",
    "        roi_feats_mask = self.cast(roi_feats_mask, self.cast_type)\n",
    "        rcnn_mask_fb_loss = self.rcnn_mask(roi_feats_mask,\n",
    "                                           rcnn_pos_labels,\n",
    "                                           rcnn_pos_mask_squeeze,\n",
    "                                           rcnn_pos_masks_fb)\n",
    "\n",
    "        rcnn_loss = self.rcnn_loss_cls_weight * rcnn_cls_loss + self.rcnn_loss_reg_weight * rcnn_reg_loss + \\\n",
    "                    self.rcnn_loss_mask_fb_weight * rcnn_mask_fb_loss\n",
    "        output += (rpn_loss, rcnn_loss, rpn_cls_loss, rpn_reg_loss,\n",
    "                   rcnn_cls_loss, rcnn_reg_loss, rcnn_mask_fb_loss)\n",
    "        return output\n",
    "\n",
    "    def get_output_eval(self, x, bboxes_all, rcnn_cls_loss, rcnn_reg_loss, rcnn_masks, img_metas):\n",
    "        mask_fb_pred_all = self.rcnn_mask_test(x, bboxes_all, rcnn_cls_loss, rcnn_reg_loss)\n",
    "        output = self.get_det_bboxes(rcnn_cls_loss, rcnn_reg_loss, rcnn_masks, bboxes_all,\n",
    "                                     img_metas, mask_fb_pred_all)\n",
    "        return output\n",
    "\n",
    "    def get_det_bboxes(self, cls_logits, reg_logits, mask_logits, rois, img_metas, mask_fb_pred_all):\n",
    "        \"\"\"Get the actual detection box.\"\"\"\n",
    "        scores = self.softmax(cls_logits / self.value)\n",
    "        mask_fb_logits = self.sigmoid(mask_fb_pred_all)\n",
    "\n",
    "        boxes_all = ()\n",
    "        for i in range(self.num_classes):\n",
    "            k = i * 4\n",
    "            reg_logits_i = self.squeeze(reg_logits[::, k:k+4:1])\n",
    "            out_boxes_i = self.decode(rois, reg_logits_i)\n",
    "            boxes_all += (out_boxes_i,)\n",
    "\n",
    "        img_metas_all = self.split(img_metas)\n",
    "        scores_all = self.split(scores)\n",
    "        mask_all = self.split(self.cast(mask_logits, mstype.int32))\n",
    "        mask_fb_all = self.split(mask_fb_logits)\n",
    "\n",
    "        boxes_all_with_batchsize = ()\n",
    "        for i in range(self.test_batch_size):\n",
    "            scale = self.split_shape(self.squeeze(img_metas_all[i]))\n",
    "            scale_h = scale[2]\n",
    "            scale_w = scale[3]\n",
    "            boxes_tuple = ()\n",
    "            for j in range(self.num_classes):\n",
    "                boxes_tmp = self.split(boxes_all[j])\n",
    "                out_boxes_h = boxes_tmp[i] / scale_h\n",
    "                out_boxes_w = boxes_tmp[i] / scale_w\n",
    "                boxes_tuple += (self.select(self.bbox_mask, out_boxes_w, out_boxes_h),)\n",
    "            boxes_all_with_batchsize += (boxes_tuple,)\n",
    "\n",
    "        output = self.multiclass_nms(boxes_all_with_batchsize, scores_all, mask_all, mask_fb_all)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def multiclass_nms(self, boxes_all, scores_all, mask_all, mask_fb_all):\n",
    "        \"\"\"Multiscale postprocessing.\"\"\"\n",
    "        all_bboxes = ()\n",
    "        all_labels = ()\n",
    "        all_masks = ()\n",
    "        all_masks_fb = ()\n",
    "\n",
    "        for i in range(self.test_batch_size):\n",
    "            bboxes = boxes_all[i]\n",
    "            scores = scores_all[i]\n",
    "            masks = self.cast(mask_all[i], mstype.bool_)\n",
    "            masks_fb = mask_fb_all[i]\n",
    "            _mask_fb_all = self.split_fb_mask(masks_fb)\n",
    "\n",
    "            res_boxes_tuple = ()\n",
    "            res_labels_tuple = ()\n",
    "            res_masks_tuple = ()\n",
    "            res_masks_fb_tuple = ()\n",
    "\n",
    "            for j in range(self.num_classes - 1):\n",
    "                k = j + 1\n",
    "                _cls_scores = scores[::, k:k + 1:1]\n",
    "                _bboxes = self.squeeze(bboxes[k])\n",
    "                _mask_o = self.reshape(masks, (self.rpn_max_num, 1))\n",
    "                _masks_fb = self.squeeze(_mask_fb_all[k])\n",
    "\n",
    "                cls_mask = self.greater(_cls_scores, self.test_score_thresh)\n",
    "                _mask = self.logicand(_mask_o, cls_mask)\n",
    "\n",
    "                _reg_mask = self.cast(self.tile(self.cast(_mask, mstype.int32), (1, 4)), mstype.bool_)\n",
    "\n",
    "                _bboxes = self.select(_reg_mask, _bboxes, self.test_box_zeros)\n",
    "                _fb_mask = self.expand_dims(_mask, -1)\n",
    "                _mask_fb_mask = self.cast(self.tile(self.cast(_fb_mask, mstype.int32), (1, 28, 28)), mstype.bool_)\n",
    "                _masks_fb = self.select(_mask_fb_mask, _masks_fb, self.test_mask_fb_zeros)\n",
    "                _cls_scores = self.select(_mask, _cls_scores, self.test_score_zeros)\n",
    "                __cls_scores = self.squeeze(_cls_scores)\n",
    "                scores_sorted, topk_inds = self.test_topk(__cls_scores, self.rpn_max_num)\n",
    "                topk_inds = self.reshape(topk_inds, (self.rpn_max_num, 1))\n",
    "                scores_sorted = self.reshape(scores_sorted, (self.rpn_max_num, 1))\n",
    "                _bboxes_sorted = self.gather(_bboxes, topk_inds)\n",
    "                _mask_fb_sorted = self.gather(_masks_fb, topk_inds)\n",
    "                _mask_sorted = self.gather(_mask, topk_inds)\n",
    "\n",
    "                scores_sorted = self.tile(scores_sorted, (1, 4))\n",
    "                cls_dets = self.concat_1((_bboxes_sorted, scores_sorted))\n",
    "                cls_dets = P.Slice()(cls_dets, (0, 0), (self.rpn_max_num, 5))\n",
    "\n",
    "                cls_dets, _index, _mask_nms = self.nms_test(cls_dets)\n",
    "                _index = self.reshape(_index, (self.rpn_max_num, 1))\n",
    "                _mask_nms = self.reshape(_mask_nms, (self.rpn_max_num, 1))\n",
    "\n",
    "                _mask_n = self.gather(_mask_sorted, _index)\n",
    "                _mask_n = self.logicand(_mask_n, _mask_nms)\n",
    "\n",
    "                _mask_fb = self.gather(_mask_fb_sorted, _index)\n",
    "\n",
    "                cls_labels = self.oneslike(_index) * j\n",
    "                res_boxes_tuple += (cls_dets,)\n",
    "                res_labels_tuple += (cls_labels,)\n",
    "                res_masks_tuple += (_mask_n,)\n",
    "                res_masks_fb_tuple += (_mask_fb,)\n",
    "\n",
    "            res_boxes_start = self.concat(res_boxes_tuple[:self.concat_start])\n",
    "            res_labels_start = self.concat(res_labels_tuple[:self.concat_start])\n",
    "            res_masks_start = self.concat(res_masks_tuple[:self.concat_start])\n",
    "            res_masks_fb_start = self.concat(res_masks_fb_tuple[:self.concat_start])\n",
    "\n",
    "            res_boxes_end = self.concat(res_boxes_tuple[self.concat_start:self.concat_end])\n",
    "            res_labels_end = self.concat(res_labels_tuple[self.concat_start:self.concat_end])\n",
    "            res_masks_end = self.concat(res_masks_tuple[self.concat_start:self.concat_end])\n",
    "            res_masks_fb_end = self.concat(res_masks_fb_tuple[self.concat_start:self.concat_end])\n",
    "\n",
    "            res_boxes = self.concat((res_boxes_start, res_boxes_end))\n",
    "            res_labels = self.concat((res_labels_start, res_labels_end))\n",
    "            res_masks = self.concat((res_masks_start, res_masks_end))\n",
    "            res_masks_fb = self.concat((res_masks_fb_start, res_masks_fb_end))\n",
    "\n",
    "            reshape_size = (self.num_classes - 1) * self.rpn_max_num\n",
    "            res_boxes = self.reshape(res_boxes, (1, reshape_size, 5))\n",
    "            res_labels = self.reshape(res_labels, (1, reshape_size, 1))\n",
    "            res_masks = self.reshape(res_masks, (1, reshape_size, 1))\n",
    "            res_masks_fb = self.reshape(res_masks_fb, (1, reshape_size, 28, 28))\n",
    "\n",
    "            all_bboxes += (res_boxes,)\n",
    "            all_labels += (res_labels,)\n",
    "            all_masks += (res_masks,)\n",
    "            all_masks_fb += (res_masks_fb,)\n",
    "\n",
    "        all_bboxes = self.concat(all_bboxes)\n",
    "        all_labels = self.concat(all_labels)\n",
    "        all_masks = self.concat(all_masks)\n",
    "        all_masks_fb = self.concat(all_masks_fb)\n",
    "        return all_bboxes, all_labels, all_masks, all_masks_fb\n",
    "\n",
    "    def get_anchors(self, featmap_sizes):\n",
    "        \"\"\"Get anchors according to feature map sizes.\n",
    "\n",
    "        Args:\n",
    "            featmap_sizes (list[tuple]): Multi-level feature map sizes.\n",
    "            img_metas (list[dict]): Image meta info.\n",
    "\n",
    "        Returns:\n",
    "            tuple: anchors of each image, valid flags of each image\n",
    "        \"\"\"\n",
    "        num_levels = len(featmap_sizes)\n",
    "\n",
    "        # since feature map sizes of all images are the same, we only compute\n",
    "        # anchors for one time\n",
    "        multi_level_anchors = ()\n",
    "        for i in range(num_levels):\n",
    "            anchors = self.anchor_generators[i].grid_anchors(\n",
    "                featmap_sizes[i], self.anchor_strides[i])\n",
    "            multi_level_anchors += (Tensor(anchors.astype(self.np_cast_type)),)\n",
    "\n",
    "        return multi_level_anchors\n",
    "\n",
    "    def rcnn_mask_test(self, x, rois, cls_pred, reg_pred):\n",
    "        \"\"\"Prediction masks in an images by the bounding boxes\n",
    "        \"\"\"\n",
    "        cls_scores = self.softmax(cls_pred / self.value)\n",
    "\n",
    "        cls_scores_all = self.split(cls_scores)\n",
    "        reg_pred = self.reshape(reg_pred, (-1, self.num_classes, 4))\n",
    "        reg_pred_all = self.split(reg_pred)\n",
    "        rois_all = self.split(rois)\n",
    "        boxes_tuple = ()\n",
    "        for i in range(self.test_batch_size):\n",
    "            cls_score_max_index, _ = self.argmax_with_value(cls_scores_all[i])\n",
    "            cls_score_max_index = self.cast(self.onehot(cls_score_max_index, self.num_classes,\n",
    "                                                        self.on_value, self.off_value), self.cast_type)\n",
    "            cls_score_max_index = self.expand_dims(cls_score_max_index, -1)\n",
    "            cls_score_max_index = self.tile(cls_score_max_index, (1, 1, 4))\n",
    "            reg_pred_max = reg_pred_all[i] * cls_score_max_index\n",
    "            reg_pred_max = self.reducesum(reg_pred_max, 1)\n",
    "            out_boxes_i = self.decode(rois_all[i], reg_pred_max)\n",
    "            boxes_tuple += (out_boxes_i,)\n",
    "\n",
    "        boxes_all = self.concat(boxes_tuple)\n",
    "        boxes_rois = self.concat_1((self.roi_align_index_test_tensor, boxes_all))\n",
    "        boxes_rois = self.cast(boxes_rois, self.cast_type)\n",
    "        roi_feats_mask_test = self.roi_align_mask_test(boxes_rois,\n",
    "                                                       self.cast(x[0], mstype.float32),\n",
    "                                                       self.cast(x[1], mstype.float32),\n",
    "                                                       self.cast(x[2], mstype.float32),\n",
    "                                                       self.cast(x[3], mstype.float32))\n",
    "        roi_feats_mask_test = self.cast(roi_feats_mask_test, self.cast_type)\n",
    "        mask_fb_pred_all = self.rcnn_mask(roi_feats_mask_test)\n",
    "        return mask_fb_pred_all\n",
    "\n",
    "\n",
    "def bbox_overlaps(bboxes1, bboxes2, mode='iou'):\n",
    "    \"\"\"Calculate the ious between each bbox of bboxes1 and bboxes2.\n",
    "\n",
    "    Args:\n",
    "        bboxes1(ndarray): shape (n, 4)\n",
    "        bboxes2(ndarray): shape (k, 4)\n",
    "        mode(str): iou (intersection over union) or iof (intersection\n",
    "            over foreground)\n",
    "\n",
    "    Returns:\n",
    "        ious(ndarray): shape (n, k)\n",
    "    \"\"\"\n",
    "\n",
    "    assert mode in ['iou', 'iof']\n",
    "\n",
    "    bboxes1 = bboxes1.astype(np.float32)\n",
    "    bboxes2 = bboxes2.astype(np.float32)\n",
    "    rows = bboxes1.shape[0]\n",
    "    cols = bboxes2.shape[0]\n",
    "    ious = np.zeros((rows, cols), dtype=np.float32)\n",
    "    if rows * cols == 0:\n",
    "        return ious\n",
    "    exchange = False\n",
    "    if bboxes1.shape[0] > bboxes2.shape[0]:\n",
    "        bboxes1, bboxes2 = bboxes2, bboxes1\n",
    "        ious = np.zeros((cols, rows), dtype=np.float32)\n",
    "        exchange = True\n",
    "    area1 = (bboxes1[:, 2] - bboxes1[:, 0] + 1) * (bboxes1[:, 3] - bboxes1[:, 1] + 1)\n",
    "    area2 = (bboxes2[:, 2] - bboxes2[:, 0] + 1) * (bboxes2[:, 3] - bboxes2[:, 1] + 1)\n",
    "    for i in range(bboxes1.shape[0]):\n",
    "        x_start = np.maximum(bboxes1[i, 0], bboxes2[:, 0])\n",
    "        y_start = np.maximum(bboxes1[i, 1], bboxes2[:, 1])\n",
    "        x_end = np.minimum(bboxes1[i, 2], bboxes2[:, 2])\n",
    "        y_end = np.minimum(bboxes1[i, 3], bboxes2[:, 3])\n",
    "        overlap = np.maximum(x_end - x_start + 1, 0) * np.maximum(\n",
    "            y_end - y_start + 1, 0)\n",
    "        if mode == 'iou':\n",
    "            union = area1[i] + area2 - overlap\n",
    "        else:\n",
    "            union = area1[i] if not exchange else area2\n",
    "        ious[i, :] = overlap / union\n",
    "    if exchange:\n",
    "        ious = ious.T\n",
    "    return ious\n",
    "\n",
    "\n",
    "class PhotoMetricDistortion:\n",
    "    \"\"\"Photo Metric Distortion\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 brightness_delta=32,\n",
    "                 contrast_range=(0.5, 1.5),\n",
    "                 saturation_range=(0.5, 1.5),\n",
    "                 hue_delta=18):\n",
    "        self.brightness_delta = brightness_delta\n",
    "        self.contrast_lower, self.contrast_upper = contrast_range\n",
    "        self.saturation_lower, self.saturation_upper = saturation_range\n",
    "        self.hue_delta = hue_delta\n",
    "\n",
    "    def __call__(self, img, boxes, labels):\n",
    "        # random brightness\n",
    "        img = img.astype('float32')\n",
    "\n",
    "        if random.randint(2):\n",
    "            delta = random.uniform(-self.brightness_delta,\n",
    "                                   self.brightness_delta)\n",
    "            img += delta\n",
    "\n",
    "        # mode == 0 --> do random contrast first\n",
    "        # mode == 1 --> do random contrast last\n",
    "        mode = random.randint(2)\n",
    "        if mode == 1:\n",
    "            if random.randint(2):\n",
    "                alpha = random.uniform(self.contrast_lower,\n",
    "                                       self.contrast_upper)\n",
    "                img *= alpha\n",
    "\n",
    "        # convert color from BGR to HSV\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # random saturation\n",
    "        if random.randint(2):\n",
    "            img[..., 1] *= random.uniform(self.saturation_lower,\n",
    "                                          self.saturation_upper)\n",
    "\n",
    "        # random hue\n",
    "        if random.randint(2):\n",
    "            img[..., 0] += random.uniform(-self.hue_delta, self.hue_delta)\n",
    "            img[..., 0][img[..., 0] > 360] -= 360\n",
    "            img[..., 0][img[..., 0] < 0] += 360\n",
    "\n",
    "        # convert color from HSV to BGR\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "        # random contrast\n",
    "        if mode == 0:\n",
    "            if random.randint(2):\n",
    "                alpha = random.uniform(self.contrast_lower,\n",
    "                                       self.contrast_upper)\n",
    "                img *= alpha\n",
    "\n",
    "        # randomly swap channels\n",
    "        if random.randint(2):\n",
    "            img = img[..., random.permutation(3)]\n",
    "\n",
    "        return img, boxes, labels\n",
    "\n",
    "\n",
    "class Expand:\n",
    "    \"\"\"expand image\"\"\"\n",
    "\n",
    "    def __init__(self, mean=(0, 0, 0), to_rgb=True, ratio_range=(1, 4)):\n",
    "        if to_rgb:\n",
    "            self.mean = mean[::-1]\n",
    "        else:\n",
    "            self.mean = mean\n",
    "        self.min_ratio, self.max_ratio = ratio_range\n",
    "\n",
    "    def __call__(self, img, boxes, labels, mask):\n",
    "        if random.randint(2):\n",
    "            return img, boxes, labels, mask\n",
    "\n",
    "        h, w, c = img.shape\n",
    "        ratio = random.uniform(self.min_ratio, self.max_ratio)\n",
    "        expand_img = np.full((int(h * ratio), int(w * ratio), c),\n",
    "                             self.mean).astype(img.dtype)\n",
    "        left = int(random.uniform(0, w * ratio - w))\n",
    "        top = int(random.uniform(0, h * ratio - h))\n",
    "        expand_img[top:top + h, left:left + w] = img\n",
    "        img = expand_img\n",
    "        boxes += np.tile((left, top), 2)\n",
    "\n",
    "        mask_count, mask_h, mask_w = mask.shape\n",
    "        expand_mask = np.zeros((mask_count, int(mask_h * ratio), int(mask_w * ratio))).astype(mask.dtype)\n",
    "        expand_mask[:, top:top + h, left:left + w] = mask\n",
    "        mask = expand_mask\n",
    "\n",
    "        return img, boxes, labels, mask\n",
    "\n",
    "\n",
    "class LossCallBack(Callback):\n",
    "    \"\"\"\n",
    "    Monitor the loss in training.\n",
    "\n",
    "    If the loss is NAN or INF terminating training.\n",
    "\n",
    "    Note:\n",
    "        If per_print_times is 0 do not print loss.\n",
    "\n",
    "    Args:\n",
    "        per_print_times (int): Print loss every times. Default: 1.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, per_print_times=1, rank_id=0):\n",
    "        super(LossCallBack, self).__init__()\n",
    "        if not isinstance(per_print_times, int) or per_print_times < 0:\n",
    "            raise ValueError(\"print_step must be int and >= 0.\")\n",
    "        self._per_print_times = per_print_times\n",
    "        self.count = 0\n",
    "        self.loss_sum = 0\n",
    "        self.rank_id = rank_id\n",
    "\n",
    "        global time_stamp_init, time_stamp_first\n",
    "        if not time_stamp_init:\n",
    "            time_stamp_first = time.time()\n",
    "            time_stamp_init = True\n",
    "\n",
    "    def step_end(self, run_context):\n",
    "        cb_params = run_context.original_args()\n",
    "        loss = cb_params.net_outputs.asnumpy()\n",
    "        cur_step_in_epoch = (cb_params.cur_step_num - 1) % cb_params.batch_num + 1\n",
    "\n",
    "        self.count += 1\n",
    "        self.loss_sum += float(loss)\n",
    "\n",
    "        if self.count >= 1:\n",
    "            global time_stamp_first\n",
    "            time_stamp_current = time.time()\n",
    "            total_loss = self.loss_sum / self.count\n",
    "\n",
    "            loss_file = open(\"./loss_{}.log\".format(self.rank_id), \"a+\")\n",
    "            loss_file.write(\"%lu epoch: %s step: %s total_loss: %.5f\" %\n",
    "                            (time_stamp_current - time_stamp_first, cb_params.cur_epoch_num, cur_step_in_epoch,\n",
    "                             total_loss))\n",
    "            loss_file.write(\"\\n\")\n",
    "            loss_file.close()\n",
    "\n",
    "            self.count = 0\n",
    "            self.loss_sum = 0\n",
    "\n",
    "\n",
    "class LossNet(nn.Cell):\n",
    "    \"\"\"MaskRcnn loss method\"\"\"\n",
    "\n",
    "    def construct(self, x1, x2, x3, x4, x5, x6, x7):\n",
    "        return x1 + x2 + x3 + x4 + x5 + x6 + x7\n",
    "\n",
    "\n",
    "class WithLossCell(nn.Cell):\n",
    "    \"\"\"\n",
    "    Wrap the network with loss function to compute loss.\n",
    "\n",
    "    Args:\n",
    "        backbone (Cell): The target network to wrap.\n",
    "        loss_fn (Cell): The loss function used to compute loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, backbone, loss_fn):\n",
    "        super(WithLossCell, self).__init__(auto_prefix=False)\n",
    "        self._backbone = backbone\n",
    "        self._loss_fn = loss_fn\n",
    "\n",
    "    def construct(self, x, img_shape, gt_bboxe, gt_label, gt_num, gt_mask):\n",
    "        loss1, loss2, loss3, loss4, loss5, loss6, loss7 = self._backbone(x, img_shape, gt_bboxe, gt_label,\n",
    "                                                                         gt_num, gt_mask)\n",
    "        return self._loss_fn(loss1, loss2, loss3, loss4, loss5, loss6, loss7)\n",
    "\n",
    "    @property\n",
    "    def backbone_network(self):\n",
    "        \"\"\"\n",
    "        Get the backbone network.\n",
    "\n",
    "        Returns:\n",
    "            Cell, return backbone network.\n",
    "        \"\"\"\n",
    "        return self._backbone\n",
    "\n",
    "\n",
    "class TrainOneStepCell(nn.Cell):\n",
    "    \"\"\"\n",
    "    Network training package class.\n",
    "\n",
    "    Append an optimizer to the training network after that the construct function\n",
    "    can be called to create the backward graph.\n",
    "\n",
    "    Args:\n",
    "        network (Cell): The training network.\n",
    "        optimizer (Cell): Optimizer for updating the weights.\n",
    "        sens (Number): The adjust parameter. Default value is 1.0.\n",
    "        reduce_flag (bool): The reduce flag. Default value is False.\n",
    "        mean (bool): Allreduce method. Default value is False.\n",
    "        degree (int): Device number. Default value is None.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, network, optimizer, sens=1.0, reduce_flag=False, mean=True, degree=None):\n",
    "        super(TrainOneStepCell, self).__init__(auto_prefix=False)\n",
    "        self.network = network\n",
    "        self.network.set_grad()\n",
    "        self.weights = ParameterTuple(network.trainable_params())\n",
    "        self.optimizer = optimizer\n",
    "        self.grad = C.GradOperation(get_by_list=True,\n",
    "                                    sens_param=True)\n",
    "\n",
    "        self.sens = Tensor((np.ones((1,)) * sens).astype(np.float32))\n",
    "\n",
    "        self.reduce_flag = reduce_flag\n",
    "        self.hyper_map = C.HyperMap()\n",
    "\n",
    "    def construct(self, x, img_shape, gt_bboxe, gt_label, gt_num, gt_mask):\n",
    "        weights = self.weights\n",
    "        loss = self.network(x, img_shape, gt_bboxe, gt_label, gt_num, gt_mask)\n",
    "        grads = self.grad(self.network, weights)(x, img_shape, gt_bboxe, gt_label, gt_num, gt_mask, self.sens)\n",
    "        if self.reduce_flag:\n",
    "            grads = self.grad_reducer(grads)\n",
    "\n",
    "        return F.depend(loss, self.optimizer(grads))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2613c2df",
   "metadata": {},
   "source": [
    "## 评估指标\n",
    "本案例的评估指标使用的pycocotools工具包中实现的指标，使用了mAP和AR。\n",
    "- mAP:AP的计算仅涉及一类。但是，在物体检测中，通常有k个类。平均平均精度（mAP）定义为k类AP的平均值:\n",
    "$$\n",
    "mAP = \\frac{ {\\textstyle \\sum_{i=1}^{K}}AP_i}{K}\n",
    "$$\n",
    "- 像AP一样，平均召回率（AR）也是可用于比较检测器性能的数值指标。本质上，AR是可以计算为召回-IoU曲线下面积的两倍：\n",
    "$$\n",
    "AR = 2\\int_{0.5}^{1} recall(o)do\n",
    "$$\n",
    "应该注意的是，出于其最初的目的（Hosang等人，2016年），召回率-IoU曲线无法区分不同的类别。但是，COCO挑战做出了这样的区分，并且其AR指标是按类别计算的，就像AP一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f66d862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco_eval(result_files, result_types, coco, max_dets=(100, 300, 1000), single_result=False):\n",
    "    \"\"\"coco eval for maskrcnn\"\"\"\n",
    "    _init_value = np.array(0.0)\n",
    "    summary_init = {\n",
    "        'Precision/mAP': _init_value,\n",
    "        'Precision/mAP@.50IOU': _init_value,\n",
    "        'Precision/mAP@.75IOU': _init_value,\n",
    "        'Precision/mAP (small)': _init_value,\n",
    "        'Precision/mAP (medium)': _init_value,\n",
    "        'Precision/mAP (large)': _init_value,\n",
    "        'Recall/AR@1': _init_value,\n",
    "        'Recall/AR@10': _init_value,\n",
    "        'Recall/AR@100': _init_value,\n",
    "        'Recall/AR@100 (small)': _init_value,\n",
    "        'Recall/AR@100 (medium)': _init_value,\n",
    "        'Recall/AR@100 (large)': _init_value,\n",
    "    }\n",
    "    anns = json.load(open(result_files['bbox']))\n",
    "    if not anns:\n",
    "        return summary_init\n",
    "    if isinstance(coco, str):\n",
    "        coco = COCO(coco)\n",
    "    assert isinstance(coco, COCO)\n",
    "\n",
    "    for res_type in result_types:\n",
    "        result_file = result_files[res_type]\n",
    "        assert result_file.endswith('.json')\n",
    "\n",
    "        coco_dets = coco.loadRes(result_file)\n",
    "        gt_img_ids = coco.getImgIds()\n",
    "        det_img_ids = coco_dets.getImgIds()\n",
    "        iou_type = 'bbox' if res_type == 'proposal' else res_type\n",
    "        cocoEval = COCOeval(coco, coco_dets, iou_type)\n",
    "        if res_type == 'proposal':\n",
    "            cocoEval.params.useCats = 0\n",
    "            cocoEval.params.maxDets = list(max_dets)\n",
    "\n",
    "        tgt_ids = gt_img_ids if not single_result else det_img_ids\n",
    "\n",
    "        if single_result:\n",
    "            res_dict = dict()\n",
    "            for id_i in tgt_ids:\n",
    "                cocoEval = COCOeval(coco, coco_dets, iou_type)\n",
    "                if res_type == 'proposal':\n",
    "                    cocoEval.params.useCats = 0\n",
    "                    cocoEval.params.maxDets = list(max_dets)\n",
    "\n",
    "                cocoEval.params.imgIds = [id_i]\n",
    "                cocoEval.evaluate()\n",
    "                cocoEval.accumulate()\n",
    "                cocoEval.summarize()\n",
    "                res_dict.update({coco.imgs[id_i]['file_name']: cocoEval.stats[1]})\n",
    "\n",
    "        cocoEval = COCOeval(coco, coco_dets, iou_type)\n",
    "        if res_type == 'proposal':\n",
    "            cocoEval.params.useCats = 0\n",
    "            cocoEval.params.maxDets = list(max_dets)\n",
    "\n",
    "        cocoEval.params.imgIds = tgt_ids\n",
    "        cocoEval.evaluate()\n",
    "        cocoEval.accumulate()\n",
    "        cocoEval.summarize()\n",
    "\n",
    "        summary_metrics = {\n",
    "            'Precision/mAP': cocoEval.stats[0],\n",
    "            'Precision/mAP@.50IOU': cocoEval.stats[1],\n",
    "            'Precision/mAP@.75IOU': cocoEval.stats[2],\n",
    "            'Precision/mAP (small)': cocoEval.stats[3],\n",
    "            'Precision/mAP (medium)': cocoEval.stats[4],\n",
    "            'Precision/mAP (large)': cocoEval.stats[5],\n",
    "            'Recall/AR@1': cocoEval.stats[6],\n",
    "            'Recall/AR@10': cocoEval.stats[7],\n",
    "            'Recall/AR@100': cocoEval.stats[8],\n",
    "            'Recall/AR@100 (small)': cocoEval.stats[9],\n",
    "            'Recall/AR@100 (medium)': cocoEval.stats[10],\n",
    "            'Recall/AR@100 (large)': cocoEval.stats[11],\n",
    "        }\n",
    "\n",
    "    return summary_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a708a98",
   "metadata": {},
   "source": [
    "## 模型训练、评估及结果可视化\n",
    "由于回调形式的模型训练不便于定位错误位置，因此本案例实现采用for循环的方式进行网络训练。for循环形式的训练整体上和pytorch差不多，但是需要注意的是mindspore将优化器进行了使用上的简化，不再需要像pytorch一样手动调用step，而是通过ops.depend将优化器的归零和更新进行了包装。\n",
    "\n",
    "评估时，会对test_dir目录下的所有图片进行评估，若需要修改评估对象，可以修改config中的test_dir，同时也需要修改test_annotations中的标注文件。\n",
    "\n",
    "结果可视化需要在评估之后才能调用，该步骤依赖于评估生成的结果文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d0658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    device_target = 'CPU'\n",
    "    # Training options\n",
    "    img_width = 1280\n",
    "    img_height = 768\n",
    "    keep_ratio = True\n",
    "    flip_ratio = 0.5\n",
    "    expand_ratio = 1.0\n",
    "    max_instance_count = 128\n",
    "    mask_shape = [28, 28]\n",
    "    # anchor\n",
    "    feature_shapes = [[192, 320], [96, 160], [48, 80], [24, 40], [12, 20]]\n",
    "    anchor_scales = [8]\n",
    "    anchor_ratios = [0.5, 1.0, 2.0]\n",
    "    anchor_strides = [4, 8, 16, 32, 64]\n",
    "    num_anchors = 3\n",
    "    # resnet\n",
    "    resnet_block = [3, 4, 6, 3]\n",
    "    resnet_in_channels = [64, 256, 512, 1024]\n",
    "    resnet_out_channels = [256, 512, 1024, 2048]\n",
    "    # fpn\n",
    "    fpn_in_channels = [256, 512, 1024, 2048]\n",
    "    fpn_out_channels = 256\n",
    "    fpn_num_outs = 5\n",
    "    # rpn\n",
    "    rpn_in_channels = 256\n",
    "    rpn_feat_channels = 256\n",
    "    rpn_loss_cls_weight = 1.0\n",
    "    rpn_loss_reg_weight = 1.0\n",
    "    rpn_cls_out_channels = 1\n",
    "    rpn_target_means = [0., 0., 0., 0.]\n",
    "    rpn_target_stds = [1.0, 1.0, 1.0, 1.0]\n",
    "    # rpn train\n",
    "    rpn_proposal_nms_across_levels = False\n",
    "    rpn_proposal_nms_pre = 2000\n",
    "    rpn_proposal_nms_post = 2000\n",
    "    rpn_proposal_max_num = 2000\n",
    "    rpn_proposal_nms_thr = 0.7\n",
    "    rpn_proposal_min_bbox_size = 0\n",
    "    # rpn test\n",
    "    rpn_nms_across_levels = False\n",
    "    rpn_nms_pre = 1000\n",
    "    rpn_nms_post = 1000\n",
    "    rpn_max_num = 1000\n",
    "    rpn_nms_thr = 0.5\n",
    "    rpn_min_bbox_min_size = 0\n",
    "    # bbox assign sampler\n",
    "    neg_iou_thr = 0.3\n",
    "    pos_iou_thr = 0.7\n",
    "    min_pos_iou = 0.3\n",
    "    num_bboxes = 245520\n",
    "    num_gts = 128\n",
    "    num_expected_neg = 256\n",
    "    num_expected_pos = 128\n",
    "    # bbox assign sampler stage2\n",
    "    neg_iou_thr_stage2 = 0.5\n",
    "    pos_iou_thr_stage2 = 0.5\n",
    "    min_pos_iou_stage2 = 0.5\n",
    "    num_bboxes_stage2 = 2000\n",
    "    num_expected_pos_stage2 = 128\n",
    "    num_expected_neg_stage2 = 512\n",
    "    num_expected_total_stage2 = 512\n",
    "    # rcnn\n",
    "    rcnn_num_layers = 2\n",
    "    rcnn_in_channels = 256\n",
    "    rcnn_fc_out_channels = 1024\n",
    "    rcnn_mask_out_channels = 256\n",
    "    rcnn_loss_cls_weight = 1\n",
    "    rcnn_loss_reg_weight = 1\n",
    "    rcnn_loss_mask_fb_weight = 1\n",
    "    rcnn_target_means = [0., 0., 0., 0.]\n",
    "    rcnn_target_stds = [0.1, 0.1, 0.2, 0.2]\n",
    "    # proposal\n",
    "    activate_num_classes = 2\n",
    "    use_sigmoid_cls = True\n",
    "    # test proposal\n",
    "    test_score_thr = 0.002\n",
    "    test_iou_thr = 0.3\n",
    "    test_max_per_img = 100\n",
    "    test_batch_size = 1\n",
    "    rpn_head_use_sigmoid = True\n",
    "    rpn_head_weight = 1.0\n",
    "    mask_thr_binary = 0.5\n",
    "    # roi align\n",
    "    class roi_layer:\n",
    "        type = 'RoIAlign'\n",
    "        out_size = 7\n",
    "        mask_out_size = 14\n",
    "        sample_num = 2\n",
    "    roi_align_out_channels = 256\n",
    "    roi_align_featmap_strides = [4, 8, 16, 32]\n",
    "    roi_align_finest_scale = 56\n",
    "    roi_sample_num = 640\n",
    "    # train\n",
    "    batch_size = 8\n",
    "    loss_scale = 1024\n",
    "    momentum = 0.91\n",
    "    weight_decay = 0.0001  # 1e-4\n",
    "    pretrain_epoch_size = 0\n",
    "    epoch_size = 20\n",
    "\n",
    "    num_classes = 81\n",
    "    test_dir = 'test_img'\n",
    "    mindrecord_dir = 'val2017'\n",
    "    instance_set = \"annotations/instances_{}.json\"\n",
    "    coco_root = '.'\n",
    "    val_data_type = 'val2017'\n",
    "    train_data_type = 'val2017'\n",
    "    coco_classes = ['background', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "                     'train', 'truck', 'boat', 'traffic light', 'fire hydrant',\n",
    "                     'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog',\n",
    "                     'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra',\n",
    "                     'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "                     'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "                     'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "                     'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "                     'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "                     'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "                     'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "                     'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "                     'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',\n",
    "                     'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "                     'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "    \n",
    "def rescale_with_tuple(img, scale):\n",
    "    h, w = img.shape[:2]\n",
    "    scale_factor = min(max(scale) / max(h, w), min(scale) / min(h, w))\n",
    "    new_size = int(w * float(scale_factor) + 0.5), int(h * float(scale_factor) + 0.5)\n",
    "    rescaled_img = cv2.resize(img, new_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return rescaled_img, scale_factor\n",
    "\n",
    "\n",
    "def rescale_with_factor(img, scale_factor):\n",
    "    h, w = img.shape[:2]\n",
    "    new_size = int(w * float(scale_factor) + 0.5), int(h * float(scale_factor) + 0.5)\n",
    "    return cv2.resize(img, new_size, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "\n",
    "def rescale_column(img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask):\n",
    "    \"\"\"rescale operation for image\"\"\"\n",
    "    img_data, scale_factor = rescale_with_tuple(img, (config.img_width, config.img_height))\n",
    "    if img_data.shape[0] > config.img_height:\n",
    "        img_data, scale_factor2 = rescale_with_tuple(img_data, (config.img_height, config.img_height))\n",
    "        scale_factor = scale_factor*scale_factor2\n",
    "\n",
    "    gt_bboxes = gt_bboxes * scale_factor\n",
    "    gt_bboxes[:, 0::2] = np.clip(gt_bboxes[:, 0::2], 0, img_data.shape[1] - 1)\n",
    "    gt_bboxes[:, 1::2] = np.clip(gt_bboxes[:, 1::2], 0, img_data.shape[0] - 1)\n",
    "\n",
    "    gt_mask_data = np.array([\n",
    "        rescale_with_factor(mask, scale_factor)\n",
    "        for mask in gt_mask\n",
    "    ])\n",
    "\n",
    "    pad_h = config.img_height - img_data.shape[0]\n",
    "    pad_w = config.img_width - img_data.shape[1]\n",
    "    assert ((pad_h >= 0) and (pad_w >= 0))\n",
    "\n",
    "    pad_img_data = np.zeros((config.img_height, config.img_width, 3)).astype(img_data.dtype)\n",
    "    pad_img_data[0:img_data.shape[0], 0:img_data.shape[1], :] = img_data\n",
    "\n",
    "    mask_count, mask_h, mask_w = gt_mask_data.shape\n",
    "    pad_mask = np.zeros((mask_count, config.img_height, config.img_width)).astype(gt_mask_data.dtype)\n",
    "    pad_mask[:, 0:mask_h, 0:mask_w] = gt_mask_data\n",
    "\n",
    "    img_shape = (config.img_height, config.img_width, 1.0)\n",
    "    img_shape = np.asarray(img_shape, dtype=np.float32)\n",
    "\n",
    "    return  (pad_img_data, img_shape, gt_bboxes, gt_label, gt_num, pad_mask)\n",
    "\n",
    "\n",
    "def rescale_column_test(img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask):\n",
    "    \"\"\"rescale operation for image of eval\"\"\"\n",
    "    img_data, scale_factor = rescale_with_tuple(img, (config.img_width, config.img_height))\n",
    "    if img_data.shape[0] > config.img_height:\n",
    "        img_data, scale_factor2 = rescale_with_tuple(img_data, (config.img_height, config.img_height))\n",
    "        scale_factor = scale_factor*scale_factor2\n",
    "\n",
    "    pad_h = config.img_height - img_data.shape[0]\n",
    "    pad_w = config.img_width - img_data.shape[1]\n",
    "    assert ((pad_h >= 0) and (pad_w >= 0))\n",
    "\n",
    "    pad_img_data = np.zeros((config.img_height, config.img_width, 3)).astype(img_data.dtype)\n",
    "    pad_img_data[0:img_data.shape[0], 0:img_data.shape[1], :] = img_data\n",
    "\n",
    "    img_shape = np.append(img_shape, (scale_factor, scale_factor))\n",
    "    img_shape = np.asarray(img_shape, dtype=np.float32)\n",
    "\n",
    "    return  (pad_img_data, img_shape, gt_bboxes, gt_label, gt_num, gt_mask)\n",
    "\n",
    "\n",
    "def resize_column(img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask):\n",
    "    \"\"\"resize operation for image\"\"\"\n",
    "    img_data = img\n",
    "    h, w = img_data.shape[:2]\n",
    "    img_data = cv2.resize(img_data, (config.img_width, config.img_height), interpolation=cv2.INTER_LINEAR)\n",
    "    h_scale = config.img_height / h\n",
    "    w_scale = config.img_width / w\n",
    "\n",
    "    scale_factor = np.array(\n",
    "        [w_scale, h_scale, w_scale, h_scale], dtype=np.float32)\n",
    "    img_shape = (config.img_height, config.img_width, 1.0)\n",
    "    img_shape = np.asarray(img_shape, dtype=np.float32)\n",
    "\n",
    "    gt_bboxes = gt_bboxes * scale_factor\n",
    "    gt_bboxes[:, 0::2] = np.clip(gt_bboxes[:, 0::2], 0, img_shape[1] - 1) # x1, x2   [0, W-1]\n",
    "    gt_bboxes[:, 1::2] = np.clip(gt_bboxes[:, 1::2], 0, img_shape[0] - 1) # y1, y2   [0, H-1]\n",
    "\n",
    "    gt_mask_data = np.array([\n",
    "        cv2.resize(mask, (config.img_width, config.img_height), interpolation=cv2.INTER_NEAREST)\n",
    "        for mask in gt_mask\n",
    "    ])\n",
    "    return  (img_data, img_shape, gt_bboxes, gt_label, gt_num, gt_mask_data)\n",
    "\n",
    "\n",
    "def resize_column_test(img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask):\n",
    "    \"\"\"resize operation for image of eval\"\"\"\n",
    "    img_data = img\n",
    "    h, w = img_data.shape[:2]\n",
    "    img_data = cv2.resize(img_data, (config.img_width, config.img_height), interpolation=cv2.INTER_LINEAR)\n",
    "    h_scale = config.img_height / h\n",
    "    w_scale = config.img_width / w\n",
    "\n",
    "    img_shape = np.append(img_shape, (h_scale, w_scale))\n",
    "    img_shape = np.asarray(img_shape, dtype=np.float32)\n",
    "\n",
    "    return  (img_data, img_shape, gt_bboxes, gt_label, gt_num, gt_mask)\n",
    "\n",
    "\n",
    "def impad_to_multiple_column(img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask):\n",
    "    \"\"\"impad operation for image\"\"\"\n",
    "    img_data = cv2.copyMakeBorder(img,\n",
    "                                  0, config.img_height - img.shape[0], 0, config.img_width - img.shape[1],\n",
    "                                  cv2.BORDER_CONSTANT,\n",
    "                                  value=0)\n",
    "    img_data = img_data.astype(np.float32)\n",
    "    return (img_data, img_shape, gt_bboxes, gt_label, gt_num, gt_mask)\n",
    "\n",
    "\n",
    "def imnormalize_column(img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask):\n",
    "    \"\"\"imnormalize operation for image\"\"\"\n",
    "    # Computed from random subset of ImageNet training images\n",
    "    mean = np.asarray([123.675, 116.28, 103.53])\n",
    "    std = np.asarray([58.395, 57.12, 57.375])\n",
    "    img_data = img.copy().astype(np.float32)\n",
    "    cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB, img_data)  # inplace\n",
    "    cv2.subtract(img_data, np.float64(mean.reshape(1, -1)), img_data)  # inplace\n",
    "    cv2.multiply(img_data, 1 / np.float64(std.reshape(1, -1)), img_data)  # inplace\n",
    "\n",
    "    img_data = img_data.astype(np.float32)\n",
    "    return (img_data, img_shape, gt_bboxes, gt_label, gt_num, gt_mask)\n",
    "\n",
    "\n",
    "def flip_column(img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask):\n",
    "    \"\"\"flip operation for image\"\"\"\n",
    "    img_data = img\n",
    "    img_data = np.flip(img_data, axis=1)\n",
    "    flipped = gt_bboxes.copy()\n",
    "    _, w, _ = img_data.shape\n",
    "\n",
    "    flipped[..., 0::4] = w - gt_bboxes[..., 2::4] - 1  # x1 = W-x2-1\n",
    "    flipped[..., 2::4] = w - gt_bboxes[..., 0::4] - 1  # x2 = W-x1-1\n",
    "\n",
    "    gt_mask_data = np.array([mask[:, ::-1] for mask in gt_mask])\n",
    "\n",
    "    return  (img_data, img_shape, flipped, gt_label, gt_num, gt_mask_data)\n",
    "\n",
    "\n",
    "def transpose_column(img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask):\n",
    "    \"\"\"transpose operation for image\"\"\"\n",
    "    if context.get_context(\"device_target\") == \"CPU\" or context.get_context(\"device_target\") == \"GPU\":\n",
    "        platform_dtype = np.float32\n",
    "    else:\n",
    "        platform_dtype = np.float32\n",
    "\n",
    "    img_data = img.transpose(2, 0, 1).copy()\n",
    "    img_data = img_data.astype(platform_dtype)\n",
    "    img_shape = img_shape.astype(platform_dtype)\n",
    "    gt_bboxes = gt_bboxes.astype(platform_dtype)\n",
    "    gt_label = gt_label.astype(np.int32)\n",
    "    gt_num = gt_num.astype(bool)\n",
    "    gt_mask_data = gt_mask.astype(bool)\n",
    "\n",
    "    return (img_data, img_shape, gt_bboxes, gt_label, gt_num, gt_mask_data)\n",
    "\n",
    "\n",
    "def photo_crop_column(img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask):\n",
    "    \"\"\"photo crop operation for image\"\"\"\n",
    "    random_photo = PhotoMetricDistortion()\n",
    "    img_data, gt_bboxes, gt_label = random_photo(img, gt_bboxes, gt_label)\n",
    "\n",
    "    return (img_data, img_shape, gt_bboxes, gt_label, gt_num, gt_mask)\n",
    "\n",
    "\n",
    "def expand_column(img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask):\n",
    "    \"\"\"expand operation for image\"\"\"\n",
    "    expand = Expand()\n",
    "    img, gt_bboxes, gt_label, gt_mask = expand(img, gt_bboxes, gt_label, gt_mask)\n",
    "\n",
    "    return (img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask)\n",
    "\n",
    "\n",
    "def pad_to_max(img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask, instance_count):\n",
    "    pad_max_number = config.max_instance_count\n",
    "    gt_box_new = np.pad(gt_bboxes, ((0, pad_max_number - instance_count), (0, 0)), mode=\"constant\", constant_values=0)\n",
    "    gt_label_new = np.pad(gt_label, ((0, pad_max_number - instance_count)), mode=\"constant\", constant_values=-1)\n",
    "    gt_iscrowd_new = np.pad(gt_num, ((0, pad_max_number - instance_count)), mode=\"constant\", constant_values=1)\n",
    "    gt_iscrowd_new_revert = ~(gt_iscrowd_new.astype(bool))\n",
    "\n",
    "    return img, img_shape, gt_box_new, gt_label_new, gt_iscrowd_new_revert, gt_mask\n",
    "\n",
    "\n",
    "def preprocess_fn(image, box, mask, mask_shape, is_training):\n",
    "    \"\"\"Preprocess function for dataset.\"\"\"\n",
    "    def _infer_data(image_bgr, image_shape, gt_box_new, gt_label_new, gt_iscrowd_new_revert,\n",
    "                    gt_mask_new, instance_count):\n",
    "        image_shape = image_shape[:2]\n",
    "        input_data = image_bgr, image_shape, gt_box_new, gt_label_new, gt_iscrowd_new_revert, gt_mask_new\n",
    "\n",
    "        if config.keep_ratio:\n",
    "            input_data = rescale_column_test(*input_data)\n",
    "        else:\n",
    "            input_data = resize_column_test(*input_data)\n",
    "        input_data = imnormalize_column(*input_data)\n",
    "\n",
    "        input_data = pad_to_max(*input_data, instance_count)\n",
    "        output_data = transpose_column(*input_data)\n",
    "        return output_data\n",
    "\n",
    "    def _data_aug(image, box, mask, mask_shape, is_training):\n",
    "        \"\"\"Data augmentation function.\"\"\"\n",
    "        image_bgr = image.copy()\n",
    "        image_bgr[:, :, 0] = image[:, :, 2]\n",
    "        image_bgr[:, :, 1] = image[:, :, 1]\n",
    "        image_bgr[:, :, 2] = image[:, :, 0]\n",
    "        image_shape = image_bgr.shape[:2]\n",
    "        instance_count = box.shape[0]\n",
    "        gt_box = box[:, :4]\n",
    "        gt_label = box[:, 4]\n",
    "        gt_iscrowd = box[:, 5]\n",
    "        gt_mask = mask.copy()\n",
    "        n, h, w = mask_shape\n",
    "        gt_mask = gt_mask.reshape(n, h, w)\n",
    "        assert n == box.shape[0]\n",
    "\n",
    "        if not is_training:\n",
    "            return _infer_data(image_bgr, image_shape, gt_box, gt_label, gt_iscrowd, gt_mask, instance_count)\n",
    "\n",
    "        flip = (np.random.rand() < config.flip_ratio)\n",
    "        expand = (np.random.rand() < config.expand_ratio)\n",
    "\n",
    "        input_data = image_bgr, image_shape, gt_box, gt_label, gt_iscrowd, gt_mask\n",
    "\n",
    "        if expand:\n",
    "            input_data = expand_column(*input_data)\n",
    "        if config.keep_ratio:\n",
    "            input_data = rescale_column(*input_data)\n",
    "        else:\n",
    "            input_data = resize_column(*input_data)\n",
    "\n",
    "        input_data = imnormalize_column(*input_data)\n",
    "        if flip:\n",
    "            input_data = flip_column(*input_data)\n",
    "\n",
    "        input_data = pad_to_max(*input_data, instance_count)\n",
    "        output_data = transpose_column(*input_data)\n",
    "        return output_data\n",
    "\n",
    "    return _data_aug(image, box, mask, mask_shape, is_training)\n",
    "\n",
    "\n",
    "def annToMask(ann, height, width):\n",
    "    \"\"\"Convert annotation to RLE and then to binary mask.\"\"\"\n",
    "    from pycocotools import mask as maskHelper\n",
    "    segm = ann['segmentation']\n",
    "    if isinstance(segm, list):\n",
    "        rles = maskHelper.frPyObjects(segm, height, width)\n",
    "        rle = maskHelper.merge(rles)\n",
    "    elif isinstance(segm['counts'], list):\n",
    "        rle = maskHelper.frPyObjects(segm, height, width)\n",
    "    else:\n",
    "        rle = ann['segmentation']\n",
    "    m = maskHelper.decode(rle)\n",
    "    return m\n",
    "\n",
    "\n",
    "def bbox2result_1image(bboxes, labels, num_classes):\n",
    "    \"\"\"Convert detection results to a list of numpy arrays.\n",
    "\n",
    "    Args:\n",
    "        bboxes (Tensor): shape (n, 5)\n",
    "        labels (Tensor): shape (n, )\n",
    "        num_classes (int): class number, including background class\n",
    "\n",
    "    Returns:\n",
    "        list(ndarray): bbox results of each class\n",
    "    \"\"\"\n",
    "    if bboxes.shape[0] == 0:\n",
    "        result = [np.zeros((0, 5), dtype=np.float32) for i in range(num_classes - 1)]\n",
    "    else:\n",
    "        result = [bboxes[labels == i, :] for i in range(num_classes - 1)]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_seg_masks(mask_pred, det_bboxes, det_labels, img_meta, rescale, num_classes):\n",
    "    \"\"\"Get segmentation masks from mask_pred and bboxes\"\"\"\n",
    "    mask_pred = mask_pred.astype(np.float32)\n",
    "\n",
    "    cls_segms = [[] for _ in range(num_classes - 1)]\n",
    "    bboxes = det_bboxes[:, :4]\n",
    "    labels = det_labels + 1\n",
    "\n",
    "    ori_shape = img_meta[:2].astype(np.int32)\n",
    "    scale_factor = img_meta[2:].astype(np.int32)\n",
    "\n",
    "    if rescale:\n",
    "        img_h, img_w = ori_shape[:2]\n",
    "    else:\n",
    "        img_h = np.round(ori_shape[0] * scale_factor[0]).astype(np.int32)\n",
    "        img_w = np.round(ori_shape[1] * scale_factor[1]).astype(np.int32)\n",
    "\n",
    "    for i in range(bboxes.shape[0]):\n",
    "        bbox = (bboxes[i, :] / 1.0).astype(np.int32)\n",
    "        label = labels[i]\n",
    "        w = max(bbox[2] - bbox[0] + 1, 1)\n",
    "        h = max(bbox[3] - bbox[1] + 1, 1)\n",
    "        w = min(w, img_w - bbox[0])\n",
    "        h = min(h, img_h - bbox[1])\n",
    "        if w <= 0 or h <= 0:\n",
    "            print(\"there is invalid proposal bbox, index={} bbox={} w={} h={}\".format(i, bbox, w, h))\n",
    "            w = max(w, 1)\n",
    "            h = max(h, 1)\n",
    "        mask_pred_ = mask_pred[i, :, :]\n",
    "        im_mask = np.zeros((img_h, img_w), dtype=np.uint8)\n",
    "        bbox_mask = cv2.resize(mask_pred_, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "        bbox_mask = (bbox_mask > config.mask_thr_binary).astype(np.uint8)\n",
    "        im_mask[bbox[1]:bbox[1] + h, bbox[0]:bbox[0] + w] = bbox_mask\n",
    "\n",
    "        rle = maskUtils.encode(\n",
    "            np.array(im_mask[:, :, np.newaxis], order='F'))[0]\n",
    "        cls_segms[label - 1].append(rle)\n",
    "\n",
    "    return cls_segms\n",
    "\n",
    "\n",
    "def det2json(dataset, results):\n",
    "    \"\"\"convert det to json mode\"\"\"\n",
    "    cat_ids = dataset.getCatIds()\n",
    "    img_ids = dataset.getImgIds()\n",
    "    json_results = []\n",
    "    dataset_len = len(img_ids)\n",
    "    for idx in range(dataset_len):\n",
    "        img_id = img_ids[idx]\n",
    "        if idx == len(results): break\n",
    "        result = results[idx]\n",
    "        for label, result_label in enumerate(result):\n",
    "            bboxes = result_label\n",
    "            for i in range(bboxes.shape[0]):\n",
    "                data = dict()\n",
    "                data['image_id'] = img_id\n",
    "                data['bbox'] = xyxy2xywh(bboxes[i])\n",
    "                data['score'] = float(bboxes[i][4])\n",
    "                data['category_id'] = cat_ids[label]\n",
    "                json_results.append(data)\n",
    "    return json_results\n",
    "\n",
    "\n",
    "def xyxy2xywh(bbox):\n",
    "    _bbox = bbox.tolist()\n",
    "    return [\n",
    "        _bbox[0],\n",
    "        _bbox[1],\n",
    "        _bbox[2] - _bbox[0] + 1,\n",
    "        _bbox[3] - _bbox[1] + 1,\n",
    "        ]\n",
    "\n",
    "\n",
    "def segm2json(dataset, results):\n",
    "    \"\"\"convert segm to json mode\"\"\"\n",
    "    cat_ids = dataset.getCatIds()\n",
    "    img_ids = dataset.getImgIds()\n",
    "    bbox_json_results = []\n",
    "    segm_json_results = []\n",
    "\n",
    "    dataset_len = len(img_ids)\n",
    "    assert dataset_len == len(results)\n",
    "    for idx in range(dataset_len):\n",
    "        img_id = img_ids[idx]\n",
    "        if idx == len(results): break\n",
    "        det, seg = results[idx]\n",
    "        for label, det_label in enumerate(det):\n",
    "            bboxes = det_label\n",
    "            for i in range(bboxes.shape[0]):\n",
    "                data = dict()\n",
    "                data['image_id'] = img_id\n",
    "                data['bbox'] = xyxy2xywh(bboxes[i])\n",
    "                data['score'] = float(bboxes[i][4])\n",
    "                data['category_id'] = cat_ids[label]\n",
    "                bbox_json_results.append(data)\n",
    "\n",
    "            if len(seg) == 2:\n",
    "                segms = seg[0][label]\n",
    "                mask_score = seg[1][label]\n",
    "            else:\n",
    "                segms = seg[label]\n",
    "                mask_score = [bbox[4] for bbox in bboxes]\n",
    "            for i in range(bboxes.shape[0]):\n",
    "                data = dict()\n",
    "                data['image_id'] = img_id\n",
    "                data['score'] = float(mask_score[i])\n",
    "                data['category_id'] = cat_ids[label]\n",
    "                segms[i]['counts'] = segms[i]['counts'].decode()\n",
    "                data['segmentation'] = segms[i]\n",
    "                segm_json_results.append(data)\n",
    "    return bbox_json_results, segm_json_results\n",
    "\n",
    "\n",
    "def proposal2json(dataset, results):\n",
    "    \"\"\"convert proposal to json mode\"\"\"\n",
    "    img_ids = dataset.getImgIds()\n",
    "    json_results = []\n",
    "    dataset_len = dataset.get_dataset_size()*2\n",
    "    for idx in range(dataset_len):\n",
    "        img_id = img_ids[idx]\n",
    "        bboxes = results[idx]\n",
    "        for i in range(bboxes.shape[0]):\n",
    "            data = dict()\n",
    "            data['image_id'] = img_id\n",
    "            data['bbox'] = xyxy2xywh(bboxes[i])\n",
    "            data['score'] = float(bboxes[i][4])\n",
    "            data['category_id'] = 1\n",
    "            json_results.append(data)\n",
    "    return json_results\n",
    "\n",
    "\n",
    "def results2json(dataset, results, out_file):\n",
    "    \"\"\"convert result convert to json mode\"\"\"\n",
    "    result_files = dict()\n",
    "    if isinstance(results[0], list):\n",
    "        json_results = det2json(dataset, results)\n",
    "        result_files['bbox'] = '{}.{}.json'.format(out_file, 'bbox')\n",
    "        result_files['proposal'] = '{}.{}.json'.format(out_file, 'bbox')\n",
    "        with open(result_files['bbox'], 'w') as fp:\n",
    "            json.dump(json_results, fp)\n",
    "    elif isinstance(results[0], tuple):\n",
    "        json_results = segm2json(dataset, results)\n",
    "        result_files['bbox'] = '{}.{}.json'.format(out_file, 'bbox')\n",
    "        result_files['segm'] = '{}.{}.json'.format(out_file, 'segm')\n",
    "        with open(result_files['bbox'], 'w') as fp:\n",
    "            json.dump(json_results[0], fp)\n",
    "        with open(result_files['segm'], 'w') as fp:\n",
    "            json.dump(json_results[1], fp)\n",
    "    elif isinstance(results[0], np.ndarray):\n",
    "        json_results = proposal2json(dataset, results)\n",
    "        result_files['proposal'] = '{}.{}.json'.format(out_file, 'proposal')\n",
    "        with open(result_files['proposal'], 'w') as fp:\n",
    "            json.dump(json_results, fp)\n",
    "    else:\n",
    "        raise TypeError('invalid type of results')\n",
    "    return result_files\n",
    "\n",
    "\n",
    "def get_img_size(file_name):\n",
    "    img = Image.open(file_name)\n",
    "    return img.size\n",
    "\n",
    "def get_resize_ratio(img_size):\n",
    "    dst_width = 1280\n",
    "    dst_height = 768\n",
    "    org_width, org_height = img_size\n",
    "    resize_ratio = dst_width / org_width\n",
    "    if resize_ratio > dst_height / org_height:\n",
    "        resize_ratio = dst_height / org_height\n",
    "\n",
    "    return resize_ratio\n",
    "    \n",
    "\n",
    "def train():\n",
    "    rank = 0\n",
    "    prefix = \"MaskRcnn.mindrecord\"\n",
    "    mindrecord_dir = 'val2017'\n",
    "    mindrecord_file = os.path.join(mindrecord_dir, prefix + \"0\")\n",
    "    if rank == 0 and not os.path.exists(mindrecord_file):\n",
    "        create_mindrecord_dir(prefix, mindrecord_dir, mindrecord_file)\n",
    "    dataset = create_maskrcnn_dataset(mindrecord_file, batch_size=config.batch_size, device_num=1, rank_id=0)\n",
    "    net = MaskRCNN(config)\n",
    "    net = net.set_train()\n",
    "    loss = LossNet()\n",
    "    lr = Tensor(0.0001, mstype.float32)\n",
    "    opt = Momentum(params=net.trainable_params(), learning_rate=lr, momentum=0.9)\n",
    "\n",
    "    def forward_fn(img_data, img_metas, gt_bboxes, gt_labels, gt_num, gt_mask):\n",
    "        output = net(img_data, img_metas, gt_bboxes, gt_labels, gt_num, gt_mask)\n",
    "        l = loss(*output)\n",
    "        return l\n",
    "    grad_fn = ops.value_and_grad(forward_fn, None, opt.parameters, has_aux=False)\n",
    "\n",
    "    def train_step(img_data, img_metas, gt_bboxes, gt_labels, gt_num, gt_mask):\n",
    "        (loss), grads = grad_fn(img_data, img_metas, gt_bboxes, gt_labels, gt_num, gt_mask)\n",
    "        loss = ops.depend(loss, opt(grads))\n",
    "        return loss\n",
    "    for epoch in range(config.epoch_size):\n",
    "        step = 0\n",
    "        for data in dataset.create_dict_iterator(output_numpy=True, num_epochs=1):\n",
    "            img_data = data['image']\n",
    "            img_metas = data['image_shape']\n",
    "            gt_bboxes = data['box']\n",
    "            gt_labels = data['label']\n",
    "            gt_num = data['valid_num']\n",
    "            gt_mask = data[\"mask\"]\n",
    "            l = train_step(Tensor(img_data, dtype=mstype.float32), Tensor(img_metas, dtype=mstype.float32),\n",
    "                              Tensor(gt_bboxes, dtype=mstype.float32), Tensor(gt_labels, dtype=mstype.float32),\n",
    "                              Tensor(gt_num, dtype=mstype.float32), Tensor(gt_mask, dtype=mstype.float32))\n",
    "            print(\"epoch:\", epoch, \" step:\", step, \" loss:\", l)\n",
    "            step += 1\n",
    "    ms.save_checkpoint(net, \"./ckpt_\" + str(rank) + \"/mask_rcnn.ckpt\")\n",
    "    print('---------train done-----------')\n",
    "\n",
    "\n",
    "def eval_():\n",
    "    device_target = config.device_target\n",
    "    context.set_context(mode=context.GRAPH_MODE, device_target=device_target)\n",
    "\n",
    "    config.mindrecord_dir = os.path.join(config.coco_root, config.test_dir)\n",
    "    prefix = \"MaskRcnn_eval.mindrecord\"\n",
    "    mindrecord_dir = config.mindrecord_dir\n",
    "    mindrecord_file = os.path.join(mindrecord_dir, prefix)\n",
    "    if not os.path.exists(mindrecord_file):\n",
    "        if not os.path.isdir(mindrecord_dir):\n",
    "            os.makedirs(mindrecord_dir)\n",
    "        if os.path.isdir(config.coco_root):\n",
    "            print(\"Create Mindrecord.\")\n",
    "            data_to_mindrecord_byte_image(\"coco\", False, prefix, file_num=1)\n",
    "            print(\"Create Mindrecord Done, at {}\".format(mindrecord_dir))\n",
    "        else:\n",
    "            print(\"coco_root not exits.\")\n",
    "\n",
    "    print(\"Start Eval!\")\n",
    "\n",
    "    ds = create_maskrcnn_dataset(mindrecord_file, batch_size=config.test_batch_size, is_training=False)\n",
    "\n",
    "    net = MaskRCNN(config)\n",
    "    param_dict = load_checkpoint('./ckpt_0/mask_rcnn.ckpt')\n",
    "    load_param_into_net(net, param_dict)\n",
    "    net.set_train(False)\n",
    "\n",
    "    eval_iter = 0\n",
    "    total = ds.get_dataset_size()\n",
    "    outputs = []\n",
    "    dataset_coco = COCO('test_annotations/instances_val2017.json')\n",
    "\n",
    "    print(\"\\n========================================\\n\")\n",
    "    print(\"total images num: \", total)\n",
    "    print(\"Processing, please wait a moment.\")\n",
    "    max_num = 128\n",
    "    for data in ds.create_dict_iterator(output_numpy=True, num_epochs=1):\n",
    "\n",
    "        img_data = data['image']\n",
    "        img_metas = data['image_shape']\n",
    "        gt_bboxes = data['box']\n",
    "        gt_labels = data['label']\n",
    "        gt_num = data['valid_num']\n",
    "        gt_mask = data[\"mask\"]\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # run net\n",
    "        output = net(Tensor(img_data, dtype=mstype.float32), Tensor(img_metas, dtype=mstype.float32), Tensor(gt_bboxes, dtype=mstype.float32),\n",
    "                     Tensor(gt_labels, dtype=mstype.float32), Tensor(gt_num, dtype=mstype.float32), Tensor(gt_mask, dtype=mstype.float32))\n",
    "        end = time.time()\n",
    "        print(\"Iter {} cost time {}\".format(eval_iter, end - start))\n",
    "\n",
    "        # output\n",
    "        all_bbox = output[0]\n",
    "        all_label = output[1]\n",
    "        all_mask = output[2]\n",
    "        all_mask_fb = output[3]\n",
    "        print(all_bbox.shape)\n",
    "        print(all_mask.shape, np.sum(all_mask.asnumpy()[0]))\n",
    "\n",
    "        for j in range(config.test_batch_size):\n",
    "            all_bbox_squee = np.squeeze(all_bbox.asnumpy()[j, :, :])\n",
    "            all_label_squee = np.squeeze(all_label.asnumpy()[j, :, :])\n",
    "            all_mask_squee = np.squeeze(all_mask.asnumpy()[j, :, :])\n",
    "            all_mask_fb_squee = np.squeeze(all_mask_fb.asnumpy()[j, :, :, :])\n",
    "\n",
    "            all_bboxes_tmp_mask = all_bbox_squee[all_mask_squee, :]\n",
    "            all_labels_tmp_mask = all_label_squee[all_mask_squee]\n",
    "            all_mask_fb_tmp_mask = all_mask_fb_squee[all_mask_squee, :, :]\n",
    "\n",
    "            if all_bboxes_tmp_mask.shape[0] > max_num:\n",
    "                inds = np.argsort(-all_bboxes_tmp_mask[:, -1])\n",
    "                inds = inds[:max_num]\n",
    "                all_bboxes_tmp_mask = all_bboxes_tmp_mask[inds]\n",
    "                all_labels_tmp_mask = all_labels_tmp_mask[inds]\n",
    "                all_mask_fb_tmp_mask = all_mask_fb_tmp_mask[inds]\n",
    "\n",
    "            bbox_results = bbox2result_1image(all_bboxes_tmp_mask, all_labels_tmp_mask, config.num_classes)\n",
    "            segm_results = get_seg_masks(all_mask_fb_tmp_mask, all_bboxes_tmp_mask, all_labels_tmp_mask, img_metas[j],\n",
    "                                         True, config.num_classes)\n",
    "            outputs.append((bbox_results, segm_results))\n",
    "\n",
    "            eval_iter = eval_iter + 1\n",
    "\n",
    "    eval_types = [\"bbox\", \"segm\"]\n",
    "    result_files = results2json(dataset_coco, outputs, \"./results.pkl\")\n",
    "    metrics = coco_eval(result_files, eval_types, dataset_coco, single_result=False)\n",
    "    print(metrics)\n",
    "\n",
    "    \n",
    "def get_eval_result(bbox_file, segm_file, ann_file, img_name, img_path):\n",
    "    \"\"\" Get metrics result according to the annotation file and result file\"\"\"\n",
    "    with open(bbox_file) as b, open(segm_file) as s:\n",
    "        bboxes = json.load(b)\n",
    "        segms = json.load(s)\n",
    "        data_coco = COCO(ann_file)\n",
    "        img_id = -1\n",
    "        for k, v in data_coco.imgs.items():\n",
    "            if v['file_name'] == img_name:\n",
    "                img_id = k\n",
    "        img = cv2.imread(img_path + \"/\" + img_name)\n",
    "        img1 = img.copy()\n",
    "        for d in bboxes:\n",
    "            if d['image_id'] == img_id:\n",
    "                box = d['bbox']\n",
    "                x, y, w, h = box\n",
    "                a = (int(x), int(y))\n",
    "                b = (int(x + w), int(y + h))\n",
    "                img1 = cv2.rectangle(img1, a, b, (0, 255, 255), 2)\n",
    "                img1 = cv2.putText(img1, \"{} {:.3f}\".format(config.coco_classes[int(d['category_id'])], d['score']),\n",
    "                                   (b[0], a[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n",
    "        color = (0, 0.6, 0.6)\n",
    "        for d in segms:\n",
    "            if d['image_id'] == img_id:\n",
    "                mask = maskUtils.decode(d['segmentation'])\n",
    "                mask = np.where(mask > 0, 1, 0).astype(np.uint8)\n",
    "                for c in range(3):\n",
    "                    img[:, :, c] = np.where(mask == 1, img[:, :, c] * 0.5 + 0.5 * color[c] * 255, img[:, :, c])\n",
    "        plt.figure()\n",
    "        plt.subplot(121)\n",
    "        img1 = img1[:, :, ::-1]\n",
    "        plt.imshow(img1)\n",
    "        plt.subplot(122)\n",
    "        img = img[:, :, ::-1]\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "train()\n",
    "eval_()\n",
    "get_eval_result('results.pkl.bbox.json', 'results.pkl.segm.json', \"test_annotations/instances_val2017.json\",\n",
    "                    '000000407646.jpg', 'test_img')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb47816",
   "metadata": {},
   "source": [
    "## 本案例脚本的使用方式\n",
    "通过将\"train\"/\"eval\"/\"infer\"赋给mode即可运行训练/评估/推理。eval会对test_img中的所有图片进行指标评估，然后将标注框和分割矩阵存放到根目录下的两个json文件中。infer则会根据eval的结果，对指定图片的检测和分割进行可视化展示。\n",
    "\n",
    "所有的配置参数均在config类中，可以根据需要进行修改。\n",
    "\n",
    "\n",
    "# 总结\n",
    "本案例基于MindSpore框架针对coco数据集，完成了数据读取、数据集创建、Mask R-CNN模型构建，进行了模型训练和评估，顺利完成了预测结果的输出。通过此案例进一步加深了对Mask R-CNN模型结构和特性的理解，并结合MindSpore框架提供的文档和教程，掌握了利用Mindspore框架实现特定案例的流程，以及多种API的使用方法，为以后在实际场景中应用MindSpore框架提供支持。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce266781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
